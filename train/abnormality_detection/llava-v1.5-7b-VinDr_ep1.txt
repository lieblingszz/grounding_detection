Tue Nov 12 17:05:50 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 4090        Off |   00000000:00:08.0 Off |                  Off |
| 31%   33C    P8             21W /  450W |       7MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA GeForce RTX 4090        Off |   00000000:00:0C.0 Off |                  Off |
| 31%   35C    P8             22W /  450W |       7MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA GeForce RTX 4090        Off |   00000000:00:0E.0 Off |                  Off |
| 33%   32C    P8             19W /  450W |       7MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA GeForce RTX 4090        Off |   00000000:00:0F.0 Off |                  Off |
| 31%   33C    P8             28W /  450W |       7MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
[2024-11-12 17:06:37,749] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-12 17:07:25,655] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0,1,2,3: setting --include=localhost:0,1,2,3
[2024-11-12 17:07:25,659] [INFO] [runner.py:571:main] cmd = /cluster/home/jingma/miniconda3/envs/llava_new/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None llava/train/train_mem.py --lora_enable True --lora_r 128 --lora_alpha 256 --mm_projector_lr 2e-5 --deepspeed /cluster/home/jingma/LLaVA/scripts/zero3.json --model_name_or_path /cluster/home/jingma/LLaVA/checkpoints/llava-v1.5-7b --version v1 --data_path /cluster/home/jingma/health_mm_llm_data/vindr-cxr_detection_train.json --image_folder None --vision_tower /cluster/home/jingma/LLaVA/clip-vit-large-patch14-336 --mm_projector_type mlp2x_gelu --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 True --output_dir /cluster/home/jingma/LLaVA/checkpoints/llava-v1.5-7b-VinDr_ep1 --num_train_epochs 1 --per_device_train_batch_size 8 --per_device_eval_batch_size 4 --gradient_accumulation_steps 1 --evaluation_strategy no --save_strategy steps --save_steps 50000 --save_total_limit 1 --learning_rate 2e-4 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 1 --lazy_preprocess True --report_to wandb
[2024-11-12 17:07:27,317] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-12 17:07:28,552] [INFO] [launch.py:138:main] 0 NCCL_P2P_DISABLE=1
[2024-11-12 17:07:28,552] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}
[2024-11-12 17:07:28,552] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=4, node_rank=0
[2024-11-12 17:07:28,552] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})
[2024-11-12 17:07:28,552] [INFO] [launch.py:163:main] dist_world_size=4
[2024-11-12 17:07:28,552] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
[2024-11-12 17:07:38,161] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-12 17:07:38,191] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-12 17:07:38,225] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-12 17:07:38,480] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-12 17:08:02,129] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-12 17:08:02,156] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-12 17:08:02,156] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-12 17:08:02,158] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-12 17:08:02,159] [INFO] [comm.py:637:init_distributed] cdb=None
[W socket.cpp:436] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:663] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:663] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:663] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:663] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[2024-11-12 17:08:06,197] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 295, num_elems = 6.76B
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/cluster/home/jingma/miniconda3/envs/llava_new/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/cluster/home/jingma/miniconda3/envs/llava_new/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/cluster/home/jingma/miniconda3/envs/llava_new/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/cluster/home/jingma/miniconda3/envs/llava_new/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:  50%|█████     | 1/2 [00:49<00:49, 49.81s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:49<00:49, 49.81s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:49<00:49, 49.82s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:58<00:58, 58.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 33.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 33.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 36.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 33.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 36.34s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 36.34s/it]

Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 32.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 36.80s/it]
Adding LoRA adapters...
[2024-11-12 17:09:44,833] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 686, num_elems = 7.06B
Formatting inputs...Skip in lazy mode
/cluster/home/jingma/miniconda3/envs/llava_new/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/cluster/home/jingma/miniconda3/envs/llava_new/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/cluster/home/jingma/miniconda3/envs/llava_new/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/cluster/home/jingma/miniconda3/envs/llava_new/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Parameter Offload: Total persistent parameters: 599040 in 312 params
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.18.1
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
  0%|          | 0/469 [00:00<?, ?it/s]/cluster/home/jingma/miniconda3/envs/llava_new/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/cluster/home/jingma/miniconda3/envs/llava_new/lib/python3.9/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/cluster/home/jingma/miniconda3/envs/llava_new/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/cluster/home/jingma/miniconda3/envs/llava_new/lib/python3.9/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/cluster/home/jingma/miniconda3/envs/llava_new/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/cluster/home/jingma/miniconda3/envs/llava_new/lib/python3.9/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/cluster/home/jingma/miniconda3/envs/llava_new/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/cluster/home/jingma/miniconda3/envs/llava_new/lib/python3.9/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  0%|          | 1/469 [00:29<3:46:35, 29.05s/it]                                                 {'loss': 1.8638, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.0}
  0%|          | 1/469 [00:29<3:46:35, 29.05s/it]  0%|          | 2/469 [00:55<3:35:34, 27.70s/it]                                                 {'loss': 1.7366, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.0}
  0%|          | 2/469 [00:55<3:35:34, 27.70s/it]  1%|          | 3/469 [01:04<2:27:05, 18.94s/it]                                                 {'loss': 1.4984, 'learning_rate': 4e-05, 'epoch': 0.01}
  1%|          | 3/469 [01:04<2:27:05, 18.94s/it]  1%|          | 4/469 [01:12<1:53:26, 14.64s/it]                                                 {'loss': 1.6694, 'learning_rate': 5.333333333333333e-05, 'epoch': 0.01}
  1%|          | 4/469 [01:12<1:53:26, 14.64s/it]  1%|          | 5/469 [01:20<1:35:15, 12.32s/it]                                                 {'loss': 1.1842, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.01}
  1%|          | 5/469 [01:20<1:35:15, 12.32s/it]  1%|▏         | 6/469 [01:28<1:24:20, 10.93s/it]                                                 {'loss': 1.115, 'learning_rate': 8e-05, 'epoch': 0.01}
  1%|▏         | 6/469 [01:28<1:24:20, 10.93s/it]  1%|▏         | 7/469 [01:37<1:17:51, 10.11s/it]                                                 {'loss': 0.9257, 'learning_rate': 9.333333333333334e-05, 'epoch': 0.01}
  1%|▏         | 7/469 [01:37<1:17:51, 10.11s/it]  2%|▏         | 8/469 [01:45<1:13:24,  9.55s/it]                                                 {'loss': 0.8558, 'learning_rate': 0.00010666666666666667, 'epoch': 0.02}
  2%|▏         | 8/469 [01:45<1:13:24,  9.55s/it]  2%|▏         | 9/469 [01:53<1:10:12,  9.16s/it]                                                 {'loss': 0.8005, 'learning_rate': 0.00012, 'epoch': 0.02}
  2%|▏         | 9/469 [01:53<1:10:12,  9.16s/it]  2%|▏         | 10/469 [02:02<1:07:44,  8.86s/it]                                                  {'loss': 0.6827, 'learning_rate': 0.00013333333333333334, 'epoch': 0.02}
  2%|▏         | 10/469 [02:02<1:07:44,  8.86s/it]  2%|▏         | 11/469 [02:10<1:06:13,  8.68s/it]                                                  {'loss': 0.6157, 'learning_rate': 0.00014666666666666666, 'epoch': 0.02}
  2%|▏         | 11/469 [02:10<1:06:13,  8.68s/it]  3%|▎         | 12/469 [02:18<1:04:36,  8.48s/it]                                                  {'loss': 0.5579, 'learning_rate': 0.00016, 'epoch': 0.03}
  3%|▎         | 12/469 [02:18<1:04:36,  8.48s/it]  3%|▎         | 13/469 [02:26<1:04:05,  8.43s/it]                                                  {'loss': 0.5299, 'learning_rate': 0.00017333333333333334, 'epoch': 0.03}
  3%|▎         | 13/469 [02:26<1:04:05,  8.43s/it]  3%|▎         | 14/469 [02:35<1:04:03,  8.45s/it]                                                  {'loss': 0.4374, 'learning_rate': 0.0001866666666666667, 'epoch': 0.03}
  3%|▎         | 14/469 [02:35<1:04:03,  8.45s/it]  3%|▎         | 15/469 [02:43<1:03:39,  8.41s/it]                                                  {'loss': 0.561, 'learning_rate': 0.0002, 'epoch': 0.03}
  3%|▎         | 15/469 [02:43<1:03:39,  8.41s/it]  3%|▎         | 16/469 [02:51<1:02:45,  8.31s/it]                                                  {'loss': 0.4647, 'learning_rate': 0.00019999760582268763, 'epoch': 0.03}
  3%|▎         | 16/469 [02:51<1:02:45,  8.31s/it]  4%|▎         | 17/469 [02:59<1:02:24,  8.28s/it]                                                  {'loss': 0.4811, 'learning_rate': 0.0001999904234053922, 'epoch': 0.04}
  4%|▎         | 17/469 [02:59<1:02:24,  8.28s/it]  4%|▍         | 18/469 [03:07<1:01:43,  8.21s/it]                                                  {'loss': 0.3986, 'learning_rate': 0.00019997845309203334, 'epoch': 0.04}
  4%|▍         | 18/469 [03:07<1:01:43,  8.21s/it]  4%|▍         | 19/469 [03:16<1:02:21,  8.31s/it]                                                  {'loss': 0.4062, 'learning_rate': 0.00019996169545579207, 'epoch': 0.04}
  4%|▍         | 19/469 [03:16<1:02:21,  8.31s/it]  4%|▍         | 20/469 [03:24<1:02:37,  8.37s/it]                                                  {'loss': 0.4654, 'learning_rate': 0.00019994015129908346, 'epoch': 0.04}
  4%|▍         | 20/469 [03:24<1:02:37,  8.37s/it]  4%|▍         | 21/469 [03:33<1:02:20,  8.35s/it]                                                  {'loss': 0.4305, 'learning_rate': 0.00019991382165351814, 'epoch': 0.04}
  4%|▍         | 21/469 [03:33<1:02:20,  8.35s/it]  5%|▍         | 22/469 [03:41<1:02:02,  8.33s/it]                                                  {'loss': 0.4407, 'learning_rate': 0.00019988270777985292, 'epoch': 0.05}
  5%|▍         | 22/469 [03:41<1:02:02,  8.33s/it]  5%|▍         | 23/469 [03:49<1:01:40,  8.30s/it]                                                  {'loss': 0.5023, 'learning_rate': 0.00019984681116793038, 'epoch': 0.05}
  5%|▍         | 23/469 [03:49<1:01:40,  8.30s/it]  5%|▌         | 24/469 [03:57<1:01:15,  8.26s/it]                                                  {'loss': 0.4394, 'learning_rate': 0.00019980613353660763, 'epoch': 0.05}
  5%|▌         | 24/469 [03:57<1:01:15,  8.26s/it]  5%|▌         | 25/469 [04:06<1:01:41,  8.34s/it]                                                  {'loss': 0.4156, 'learning_rate': 0.00019976067683367385, 'epoch': 0.05}
  5%|▌         | 25/469 [04:06<1:01:41,  8.34s/it]  6%|▌         | 26/469 [04:14<1:01:50,  8.38s/it]                                                  {'loss': 0.3274, 'learning_rate': 0.00019971044323575728, 'epoch': 0.06}
  6%|▌         | 26/469 [04:14<1:01:50,  8.38s/it]  6%|▌         | 27/469 [04:23<1:01:12,  8.31s/it]                                                  {'loss': 0.4676, 'learning_rate': 0.00019965543514822062, 'epoch': 0.06}
  6%|▌         | 27/469 [04:23<1:01:12,  8.31s/it]  6%|▌         | 28/469 [04:31<1:00:39,  8.25s/it]                                                  {'loss': 0.3621, 'learning_rate': 0.00019959565520504623, 'epoch': 0.06}
  6%|▌         | 28/469 [04:31<1:00:39,  8.25s/it]  6%|▌         | 29/469 [04:39<1:00:28,  8.25s/it]                                                  {'loss': 0.393, 'learning_rate': 0.00019953110626870979, 'epoch': 0.06}
  6%|▌         | 29/469 [04:39<1:00:28,  8.25s/it]  6%|▋         | 30/469 [04:47<1:00:18,  8.24s/it]                                                  {'loss': 0.3726, 'learning_rate': 0.00019946179143004325, 'epoch': 0.06}
  6%|▋         | 30/469 [04:47<1:00:18,  8.24s/it]  7%|▋         | 31/469 [04:56<1:01:01,  8.36s/it]                                                  {'loss': 0.4843, 'learning_rate': 0.0001993877140080869, 'epoch': 0.07}
  7%|▋         | 31/469 [04:56<1:01:01,  8.36s/it]  7%|▋         | 32/469 [05:04<1:01:23,  8.43s/it]                                                  {'loss': 0.379, 'learning_rate': 0.00019930887754993044, 'epoch': 0.07}
  7%|▋         | 32/469 [05:04<1:01:23,  8.43s/it]  7%|▋         | 33/469 [05:13<1:00:58,  8.39s/it]                                                  {'loss': 0.3968, 'learning_rate': 0.000199225285830543, 'epoch': 0.07}
  7%|▋         | 33/469 [05:13<1:00:58,  8.39s/it]  7%|▋         | 34/469 [05:21<1:00:12,  8.31s/it]                                                  {'loss': 0.3165, 'learning_rate': 0.00019913694285259256, 'epoch': 0.07}
  7%|▋         | 34/469 [05:21<1:00:12,  8.31s/it]  7%|▋         | 35/469 [05:29<59:23,  8.21s/it]                                                  {'loss': 0.3128, 'learning_rate': 0.00019904385284625424, 'epoch': 0.07}
  7%|▋         | 35/469 [05:29<59:23,  8.21s/it]  8%|▊         | 36/469 [05:37<59:04,  8.19s/it]                                                {'loss': 0.4292, 'learning_rate': 0.00019894602026900758, 'epoch': 0.08}
  8%|▊         | 36/469 [05:37<59:04,  8.19s/it]  8%|▊         | 37/469 [05:45<59:46,  8.30s/it]                                                {'loss': 0.4145, 'learning_rate': 0.00019884344980542338, 'epoch': 0.08}
  8%|▊         | 37/469 [05:46<59:46,  8.30s/it]  8%|▊         | 38/469 [05:54<59:52,  8.33s/it]                                                {'loss': 0.315, 'learning_rate': 0.0001987361463669392, 'epoch': 0.08}
  8%|▊         | 38/469 [05:54<59:52,  8.33s/it]  8%|▊         | 39/469 [06:02<59:22,  8.29s/it]                                                {'loss': 0.3987, 'learning_rate': 0.00019862411509162406, 'epoch': 0.08}
  8%|▊         | 39/469 [06:02<59:22,  8.29s/it]  9%|▊         | 40/469 [06:10<58:40,  8.21s/it]                                                {'loss': 0.4595, 'learning_rate': 0.00019850736134393286, 'epoch': 0.09}
  9%|▊         | 40/469 [06:10<58:40,  8.21s/it]  9%|▊         | 41/469 [06:18<58:06,  8.15s/it]                                                {'loss': 0.331, 'learning_rate': 0.00019838589071444903, 'epoch': 0.09}
  9%|▊         | 41/469 [06:18<58:06,  8.15s/it]  9%|▉         | 42/469 [06:26<58:16,  8.19s/it]                                                {'loss': 0.3555, 'learning_rate': 0.00019825970901961705, 'epoch': 0.09}
  9%|▉         | 42/469 [06:26<58:16,  8.19s/it]  9%|▉         | 43/469 [06:35<58:52,  8.29s/it]                                                {'loss': 0.3791, 'learning_rate': 0.00019812882230146398, 'epoch': 0.09}
  9%|▉         | 43/469 [06:35<58:52,  8.29s/it]  9%|▉         | 44/469 [06:43<59:02,  8.34s/it]                                                {'loss': 0.3412, 'learning_rate': 0.00019799323682731, 'epoch': 0.09}
  9%|▉         | 44/469 [06:43<59:02,  8.34s/it] 10%|▉         | 45/469 [06:51<58:21,  8.26s/it]                                                {'loss': 0.379, 'learning_rate': 0.00019785295908946848, 'epoch': 0.1}
 10%|▉         | 45/469 [06:51<58:21,  8.26s/it] 10%|▉         | 46/469 [07:00<58:06,  8.24s/it]                                                {'loss': 0.3762, 'learning_rate': 0.00019770799580493494, 'epoch': 0.1}
 10%|▉         | 46/469 [07:00<58:06,  8.24s/it] 10%|█         | 47/469 [07:08<57:42,  8.20s/it]                                                {'loss': 0.4637, 'learning_rate': 0.0001975583539150655, 'epoch': 0.1}
 10%|█         | 47/469 [07:08<57:42,  8.20s/it] 10%|█         | 48/469 [07:16<58:02,  8.27s/it]                                                {'loss': 0.389, 'learning_rate': 0.00019740404058524457, 'epoch': 0.1}
 10%|█         | 48/469 [07:16<58:02,  8.27s/it] 10%|█         | 49/469 [07:25<59:03,  8.44s/it]                                                {'loss': 0.4312, 'learning_rate': 0.00019724506320454153, 'epoch': 0.1}
 10%|█         | 49/469 [07:25<59:03,  8.44s/it] 11%|█         | 50/469 [07:33<58:52,  8.43s/it]                                                {'loss': 0.3913, 'learning_rate': 0.0001970814293853572, 'epoch': 0.11}
 11%|█         | 50/469 [07:33<58:52,  8.43s/it] 11%|█         | 51/469 [07:42<58:16,  8.36s/it]                                                {'loss': 0.3558, 'learning_rate': 0.00019691314696305913, 'epoch': 0.11}
 11%|█         | 51/469 [07:42<58:16,  8.36s/it] 11%|█         | 52/469 [07:50<57:42,  8.30s/it]                                                {'loss': 0.3829, 'learning_rate': 0.00019674022399560648, 'epoch': 0.11}
 11%|█         | 52/469 [07:50<57:42,  8.30s/it] 11%|█▏        | 53/469 [07:58<57:31,  8.30s/it]                                                {'loss': 0.343, 'learning_rate': 0.0001965626687631641, 'epoch': 0.11}
 11%|█▏        | 53/469 [07:58<57:31,  8.30s/it] 12%|█▏        | 54/469 [08:06<57:22,  8.29s/it]                                                {'loss': 0.3867, 'learning_rate': 0.00019638048976770628, 'epoch': 0.12}
 12%|█▏        | 54/469 [08:06<57:22,  8.29s/it] 12%|█▏        | 55/469 [08:15<57:45,  8.37s/it]                                                {'loss': 0.3399, 'learning_rate': 0.00019619369573260924, 'epoch': 0.12}
 12%|█▏        | 55/469 [08:15<57:45,  8.37s/it] 12%|█▏        | 56/469 [08:23<57:57,  8.42s/it]                                                {'loss': 0.4169, 'learning_rate': 0.00019600229560223388, 'epoch': 0.12}
 12%|█▏        | 56/469 [08:23<57:57,  8.42s/it] 12%|█▏        | 57/469 [08:32<57:30,  8.37s/it]                                                {'loss': 0.4067, 'learning_rate': 0.0001958062985414972, 'epoch': 0.12}
 12%|█▏        | 57/469 [08:32<57:30,  8.37s/it] 12%|█▏        | 58/469 [08:40<57:03,  8.33s/it]                                                {'loss': 0.3433, 'learning_rate': 0.0001956057139354335, 'epoch': 0.12}
 12%|█▏        | 58/469 [08:40<57:03,  8.33s/it] 13%|█▎        | 59/469 [08:48<56:34,  8.28s/it]                                                {'loss': 0.4576, 'learning_rate': 0.00019540055138874505, 'epoch': 0.13}
 13%|█▎        | 59/469 [08:48<56:34,  8.28s/it][2024-11-12 17:19:05,639] [WARNING] [stage3.py:1991:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
 13%|█▎        | 60/469 [08:57<57:16,  8.40s/it]                                                {'loss': 0.4295, 'learning_rate': 0.0001951908207253421, 'epoch': 0.13}
 13%|█▎        | 60/469 [08:57<57:16,  8.40s/it] 13%|█▎        | 61/469 [09:05<57:30,  8.46s/it]                                                {'loss': 0.3619, 'learning_rate': 0.00019497653198787264, 'epoch': 0.13}
 13%|█▎        | 61/469 [09:05<57:30,  8.46s/it] 13%|█▎        | 62/469 [09:14<57:19,  8.45s/it]                                                {'loss': 0.3596, 'learning_rate': 0.0001947576954372413, 'epoch': 0.13}
 13%|█▎        | 62/469 [09:14<57:19,  8.45s/it] 13%|█▎        | 63/469 [09:22<56:47,  8.39s/it]                                                {'loss': 0.4216, 'learning_rate': 0.0001945343215521182, 'epoch': 0.13}
 13%|█▎        | 63/469 [09:22<56:47,  8.39s/it] 14%|█▎        | 64/469 [09:30<56:22,  8.35s/it]                                                {'loss': 0.3733, 'learning_rate': 0.00019430642102843707, 'epoch': 0.14}
 14%|█▎        | 64/469 [09:30<56:22,  8.35s/it] 14%|█▍        | 65/469 [09:38<55:43,  8.28s/it]                                                {'loss': 0.4193, 'learning_rate': 0.00019407400477888315, 'epoch': 0.14}
 14%|█▍        | 65/469 [09:38<55:43,  8.28s/it] 14%|█▍        | 66/469 [09:47<55:28,  8.26s/it]                                                {'loss': 0.3266, 'learning_rate': 0.00019383708393237075, 'epoch': 0.14}
 14%|█▍        | 66/469 [09:47<55:28,  8.26s/it] 14%|█▍        | 67/469 [09:55<55:54,  8.35s/it]                                                {'loss': 0.4105, 'learning_rate': 0.00019359566983351013, 'epoch': 0.14}
 14%|█▍        | 67/469 [09:55<55:54,  8.35s/it] 14%|█▍        | 68/469 [10:04<55:54,  8.36s/it]                                                {'loss': 0.3255, 'learning_rate': 0.00019334977404206443, 'epoch': 0.14}
 14%|█▍        | 68/469 [10:04<55:54,  8.36s/it] 15%|█▍        | 69/469 [10:12<55:22,  8.31s/it]                                                {'loss': 0.2714, 'learning_rate': 0.00019309940833239626, 'epoch': 0.15}
 15%|█▍        | 69/469 [10:12<55:22,  8.31s/it] 15%|█▍        | 70/469 [10:20<54:52,  8.25s/it]                                                {'loss': 0.4096, 'learning_rate': 0.00019284458469290354, 'epoch': 0.15}
 15%|█▍        | 70/469 [10:20<54:52,  8.25s/it] 15%|█▌        | 71/469 [10:28<54:20,  8.19s/it]                                                {'loss': 0.3995, 'learning_rate': 0.00019258531532544585, 'epoch': 0.15}
 15%|█▌        | 71/469 [10:28<54:20,  8.19s/it] 15%|█▌        | 72/469 [10:36<54:42,  8.27s/it]                                                {'loss': 0.4248, 'learning_rate': 0.00019232161264475997, 'epoch': 0.15}
 15%|█▌        | 72/469 [10:36<54:42,  8.27s/it] 16%|█▌        | 73/469 [10:45<55:20,  8.39s/it]                                                {'loss': 0.2644, 'learning_rate': 0.00019205348927786532, 'epoch': 0.16}
 16%|█▌        | 73/469 [10:45<55:20,  8.39s/it] 16%|█▌        | 74/469 [10:53<55:13,  8.39s/it]                                                {'loss': 0.37, 'learning_rate': 0.0001917809580634596, 'epoch': 0.16}
 16%|█▌        | 74/469 [10:53<55:13,  8.39s/it] 16%|█▌        | 75/469 [11:02<54:45,  8.34s/it]                                                {'loss': 0.3866, 'learning_rate': 0.00019150403205130383, 'epoch': 0.16}
 16%|█▌        | 75/469 [11:02<54:45,  8.34s/it] 16%|█▌        | 76/469 [11:10<54:12,  8.28s/it]                                                {'loss': 0.3677, 'learning_rate': 0.00019122272450159745, 'epoch': 0.16}
 16%|█▌        | 76/469 [11:10<54:12,  8.28s/it] 16%|█▋        | 77/469 [11:18<53:42,  8.22s/it]                                                {'loss': 0.3531, 'learning_rate': 0.0001909370488843436, 'epoch': 0.16}
 16%|█▋        | 77/469 [11:18<53:42,  8.22s/it] 17%|█▋        | 78/469 [11:26<53:41,  8.24s/it]                                                {'loss': 0.3821, 'learning_rate': 0.0001906470188787039, 'epoch': 0.17}
 17%|█▋        | 78/469 [11:26<53:41,  8.24s/it] 17%|█▋        | 79/469 [11:35<53:58,  8.30s/it]                                                {'loss': 0.3541, 'learning_rate': 0.00019035264837234347, 'epoch': 0.17}
 17%|█▋        | 79/469 [11:35<53:58,  8.30s/it] 17%|█▋        | 80/469 [11:43<53:36,  8.27s/it]                                                {'loss': 0.3782, 'learning_rate': 0.00019005395146076616, 'epoch': 0.17}
 17%|█▋        | 80/469 [11:43<53:36,  8.27s/it] 17%|█▋        | 81/469 [11:51<53:14,  8.23s/it]                                                {'loss': 0.4341, 'learning_rate': 0.0001897509424466393, 'epoch': 0.17}
 17%|█▋        | 81/469 [11:51<53:14,  8.23s/it] 17%|█▋        | 82/469 [11:59<52:43,  8.18s/it]                                                {'loss': 0.389, 'learning_rate': 0.000189443635839109, 'epoch': 0.17}
 17%|█▋        | 82/469 [11:59<52:43,  8.18s/it] 18%|█▊        | 83/469 [12:07<52:34,  8.17s/it]                                                {'loss': 0.3773, 'learning_rate': 0.0001891320463531055, 'epoch': 0.18}
 18%|█▊        | 83/469 [12:07<52:34,  8.17s/it] 18%|█▊        | 84/469 [12:16<53:05,  8.27s/it]                                                {'loss': 0.4, 'learning_rate': 0.0001888161889086383, 'epoch': 0.18}
 18%|█▊        | 84/469 [12:16<53:05,  8.27s/it] 18%|█▊        | 85/469 [12:24<53:24,  8.35s/it]                                                {'loss': 0.3122, 'learning_rate': 0.00018849607863008193, 'epoch': 0.18}
 18%|█▊        | 85/469 [12:24<53:24,  8.35s/it] 18%|█▊        | 86/469 [12:32<52:48,  8.27s/it]                                                {'loss': 0.3164, 'learning_rate': 0.00018817173084545176, 'epoch': 0.18}
 18%|█▊        | 86/469 [12:32<52:48,  8.27s/it] 19%|█▊        | 87/469 [12:40<52:37,  8.27s/it]                                                {'loss': 0.3528, 'learning_rate': 0.00018784316108566996, 'epoch': 0.19}
 19%|█▊        | 87/469 [12:41<52:37,  8.27s/it] 19%|█▉        | 88/469 [12:49<52:11,  8.22s/it]                                                {'loss': 0.4029, 'learning_rate': 0.00018751038508382176, 'epoch': 0.19}
 19%|█▉        | 88/469 [12:49<52:11,  8.22s/it] 19%|█▉        | 89/469 [12:57<51:57,  8.20s/it]                                                {'loss': 0.3969, 'learning_rate': 0.00018717341877440226, 'epoch': 0.19}
 19%|█▉        | 89/469 [12:57<51:57,  8.20s/it] 19%|█▉        | 90/469 [13:05<52:15,  8.27s/it]                                                {'loss': 0.3138, 'learning_rate': 0.00018683227829255334, 'epoch': 0.19}
 19%|█▉        | 90/469 [13:05<52:15,  8.27s/it] 19%|█▉        | 91/469 [13:14<52:25,  8.32s/it]                                                {'loss': 0.3874, 'learning_rate': 0.000186486979973291, 'epoch': 0.19}
 19%|█▉        | 91/469 [13:14<52:25,  8.32s/it] 20%|█▉        | 92/469 [13:22<52:11,  8.31s/it]                                                {'loss': 0.4208, 'learning_rate': 0.0001861375403507233, 'epoch': 0.2}
 20%|█▉        | 92/469 [13:22<52:11,  8.31s/it] 20%|█▉        | 93/469 [13:30<51:54,  8.28s/it]                                                {'loss': 0.383, 'learning_rate': 0.0001857839761572586, 'epoch': 0.2}
 20%|█▉        | 93/469 [13:30<51:54,  8.28s/it] 20%|██        | 94/469 [13:38<51:45,  8.28s/it]                                                {'loss': 0.3423, 'learning_rate': 0.00018542630432280422, 'epoch': 0.2}
 20%|██        | 94/469 [13:38<51:45,  8.28s/it] 20%|██        | 95/469 [13:47<51:28,  8.26s/it]                                                {'loss': 0.4075, 'learning_rate': 0.00018506454197395606, 'epoch': 0.2}
 20%|██        | 95/469 [13:47<51:28,  8.26s/it] 20%|██        | 96/469 [13:55<52:07,  8.38s/it]                                                {'loss': 0.4007, 'learning_rate': 0.0001846987064331783, 'epoch': 0.2}
 20%|██        | 96/469 [13:55<52:07,  8.38s/it] 21%|██        | 97/469 [14:04<52:00,  8.39s/it]                                                {'loss': 0.3155, 'learning_rate': 0.0001843288152179739, 'epoch': 0.21}
 21%|██        | 97/469 [14:04<52:00,  8.39s/it] 21%|██        | 98/469 [14:12<51:15,  8.29s/it]                                                {'loss': 0.3318, 'learning_rate': 0.00018395488604004603, 'epoch': 0.21}
 21%|██        | 98/469 [14:12<51:15,  8.29s/it] 21%|██        | 99/469 [14:20<51:04,  8.28s/it]                                                {'loss': 0.3655, 'learning_rate': 0.00018357693680444976, 'epoch': 0.21}
 21%|██        | 99/469 [14:20<51:04,  8.28s/it] 21%|██▏       | 100/469 [14:28<50:41,  8.24s/it]                                                 {'loss': 0.3736, 'learning_rate': 0.00018319498560873476, 'epoch': 0.21}
 21%|██▏       | 100/469 [14:28<50:41,  8.24s/it] 22%|██▏       | 101/469 [14:36<50:42,  8.27s/it]                                                 {'loss': 0.3511, 'learning_rate': 0.00018280905074207884, 'epoch': 0.22}
 22%|██▏       | 101/469 [14:37<50:42,  8.27s/it] 22%|██▏       | 102/469 [14:45<51:16,  8.38s/it]                                                 {'loss': 0.3476, 'learning_rate': 0.00018241915068441196, 'epoch': 0.22}
 22%|██▏       | 102/469 [14:45<51:16,  8.38s/it] 22%|██▏       | 103/469 [14:54<51:25,  8.43s/it]                                                 {'loss': 0.3864, 'learning_rate': 0.00018202530410553163, 'epoch': 0.22}
 22%|██▏       | 103/469 [14:54<51:25,  8.43s/it] 22%|██▏       | 104/469 [15:02<51:05,  8.40s/it]                                                 {'loss': 0.3663, 'learning_rate': 0.00018162752986420868, 'epoch': 0.22}
 22%|██▏       | 104/469 [15:02<51:05,  8.40s/it] 22%|██▏       | 105/469 [15:10<50:20,  8.30s/it]                                                 {'loss': 0.3435, 'learning_rate': 0.00018122584700728443, 'epoch': 0.22}
 22%|██▏       | 105/469 [15:10<50:20,  8.30s/it] 23%|██▎       | 106/469 [15:18<49:52,  8.24s/it]                                                 {'loss': 0.3115, 'learning_rate': 0.00018082027476875847, 'epoch': 0.23}
 23%|██▎       | 106/469 [15:18<49:52,  8.24s/it] 23%|██▎       | 107/469 [15:27<50:24,  8.36s/it]                                                 {'loss': 0.3682, 'learning_rate': 0.0001804108325688679, 'epoch': 0.23}
 23%|██▎       | 107/469 [15:27<50:24,  8.36s/it] 23%|██▎       | 108/469 [15:35<50:48,  8.44s/it]                                                 {'loss': 0.3979, 'learning_rate': 0.0001799975400131572, 'epoch': 0.23}
 23%|██▎       | 108/469 [15:35<50:48,  8.44s/it] 23%|██▎       | 109/469 [15:44<50:52,  8.48s/it]                                                 {'loss': 0.3783, 'learning_rate': 0.0001795804168915396, 'epoch': 0.23}
 23%|██▎       | 109/469 [15:44<50:52,  8.48s/it] 23%|██▎       | 110/469 [15:52<50:24,  8.42s/it]                                                 {'loss': 0.365, 'learning_rate': 0.00017915948317734942, 'epoch': 0.23}
 23%|██▎       | 110/469 [15:52<50:24,  8.42s/it] 24%|██▎       | 111/469 [16:00<49:46,  8.34s/it]                                                 {'loss': 0.3745, 'learning_rate': 0.00017873475902638553, 'epoch': 0.24}
 24%|██▎       | 111/469 [16:01<49:46,  8.34s/it] 24%|██▍       | 112/469 [16:09<49:13,  8.27s/it]                                                 {'loss': 0.2869, 'learning_rate': 0.00017830626477594654, 'epoch': 0.24}
 24%|██▍       | 112/469 [16:09<49:13,  8.27s/it] 24%|██▍       | 113/469 [16:17<49:10,  8.29s/it]                                                 {'loss': 0.3622, 'learning_rate': 0.00017787402094385666, 'epoch': 0.24}
 24%|██▍       | 113/469 [16:17<49:10,  8.29s/it] 24%|██▍       | 114/469 [16:25<49:25,  8.35s/it]                                                 {'loss': 0.4034, 'learning_rate': 0.00017743804822748345, 'epoch': 0.24}
 24%|██▍       | 114/469 [16:26<49:25,  8.35s/it] 25%|██▍       | 115/469 [16:34<49:20,  8.36s/it]                                                 {'loss': 0.3305, 'learning_rate': 0.00017699836750274662, 'epoch': 0.25}
 25%|██▍       | 115/469 [16:34<49:20,  8.36s/it] 25%|██▍       | 116/469 [16:42<49:05,  8.34s/it]                                                 {'loss': 0.4008, 'learning_rate': 0.00017655499982311847, 'epoch': 0.25}
 25%|██▍       | 116/469 [16:42<49:05,  8.34s/it] 25%|██▍       | 117/469 [16:50<48:40,  8.30s/it]                                                 {'loss': 0.3305, 'learning_rate': 0.00017610796641861581, 'epoch': 0.25}
 25%|██▍       | 117/469 [16:50<48:40,  8.30s/it] 25%|██▌       | 118/469 [16:58<48:05,  8.22s/it]                                                 {'loss': 0.3207, 'learning_rate': 0.00017565728869478337, 'epoch': 0.25}
 25%|██▌       | 118/469 [16:58<48:05,  8.22s/it] 25%|██▌       | 119/469 [17:07<48:01,  8.23s/it]                                                 {'loss': 0.3695, 'learning_rate': 0.00017520298823166873, 'epoch': 0.25}
 25%|██▌       | 119/469 [17:07<48:01,  8.23s/it] 26%|██▌       | 120/469 [17:15<48:29,  8.34s/it]                                                 {'loss': 0.4003, 'learning_rate': 0.00017474508678278915, 'epoch': 0.26}
 26%|██▌       | 120/469 [17:15<48:29,  8.34s/it] 26%|██▌       | 121/469 [17:24<49:02,  8.45s/it]                                                 {'loss': 0.4418, 'learning_rate': 0.00017428360627408978, 'epoch': 0.26}
 26%|██▌       | 121/469 [17:24<49:02,  8.45s/it] 26%|██▌       | 122/469 [17:32<48:26,  8.38s/it]                                                 {'loss': 0.387, 'learning_rate': 0.000173818568802894, 'epoch': 0.26}
 26%|██▌       | 122/469 [17:32<48:26,  8.38s/it] 26%|██▌       | 123/469 [17:40<47:46,  8.28s/it]                                                 {'loss': 0.3788, 'learning_rate': 0.00017334999663684504, 'epoch': 0.26}
 26%|██▌       | 123/469 [17:40<47:46,  8.28s/it] 26%|██▋       | 124/469 [17:48<47:30,  8.26s/it]                                                 {'loss': 0.269, 'learning_rate': 0.00017287791221283984, 'epoch': 0.26}
 26%|██▋       | 124/469 [17:48<47:30,  8.26s/it] 27%|██▋       | 125/469 [17:57<47:20,  8.26s/it]                                                 {'loss': 0.3205, 'learning_rate': 0.00017240233813595478, 'epoch': 0.27}
 27%|██▋       | 125/469 [17:57<47:20,  8.26s/it] 27%|██▋       | 126/469 [18:05<47:40,  8.34s/it]                                                 {'loss': 0.4178, 'learning_rate': 0.00017192329717836315, 'epoch': 0.27}
 27%|██▋       | 126/469 [18:05<47:40,  8.34s/it] 27%|██▋       | 127/469 [18:14<47:53,  8.40s/it]                                                 {'loss': 0.3984, 'learning_rate': 0.0001714408122782448, 'epoch': 0.27}
 27%|██▋       | 127/469 [18:14<47:53,  8.40s/it] 27%|██▋       | 128/469 [18:22<47:29,  8.36s/it]                                                 {'loss': 0.3447, 'learning_rate': 0.00017095490653868778, 'epoch': 0.27}
 27%|██▋       | 128/469 [18:22<47:29,  8.36s/it] 28%|██▊       | 129/469 [18:30<46:58,  8.29s/it]                                                 {'loss': 0.3736, 'learning_rate': 0.000170465603226582, 'epoch': 0.28}
 28%|██▊       | 129/469 [18:30<46:58,  8.29s/it] 28%|██▊       | 130/469 [18:38<46:20,  8.20s/it]                                                 {'loss': 0.2677, 'learning_rate': 0.00016997292577150528, 'epoch': 0.28}
 28%|██▊       | 130/469 [18:38<46:20,  8.20s/it] 28%|██▊       | 131/469 [18:46<46:35,  8.27s/it]                                                 {'loss': 0.3411, 'learning_rate': 0.0001694768977646013, 'epoch': 0.28}
 28%|██▊       | 131/469 [18:47<46:35,  8.27s/it] 28%|██▊       | 132/469 [18:55<46:58,  8.36s/it]                                                 {'loss': 0.302, 'learning_rate': 0.00016897754295745008, 'epoch': 0.28}
 28%|██▊       | 132/469 [18:55<46:58,  8.36s/it] 28%|██▊       | 133/469 [19:04<47:09,  8.42s/it]                                                 {'loss': 0.334, 'learning_rate': 0.0001684748852609306, 'epoch': 0.28}
 28%|██▊       | 133/469 [19:04<47:09,  8.42s/it] 29%|██▊       | 134/469 [19:12<46:43,  8.37s/it]                                                 {'loss': 0.3219, 'learning_rate': 0.00016796894874407595, 'epoch': 0.29}
 29%|██▊       | 134/469 [19:12<46:43,  8.37s/it] 29%|██▉       | 135/469 [19:20<46:27,  8.34s/it]                                                 {'loss': 0.325, 'learning_rate': 0.0001674597576329207, 'epoch': 0.29}
 29%|██▉       | 135/469 [19:20<46:27,  8.34s/it] 29%|██▉       | 136/469 [19:28<45:47,  8.25s/it]                                                 {'loss': 0.3063, 'learning_rate': 0.000166947336309341, 'epoch': 0.29}
 29%|██▉       | 136/469 [19:28<45:47,  8.25s/it] 29%|██▉       | 137/469 [19:36<45:35,  8.24s/it]                                                 {'loss': 0.3233, 'learning_rate': 0.00016643170930988698, 'epoch': 0.29}
 29%|██▉       | 137/469 [19:37<45:35,  8.24s/it] 29%|██▉       | 138/469 [19:45<46:00,  8.34s/it]                                                 {'loss': 0.3149, 'learning_rate': 0.0001659129013246079, 'epoch': 0.29}
 29%|██▉       | 138/469 [19:45<46:00,  8.34s/it] 30%|██▉       | 139/469 [19:53<45:59,  8.36s/it]                                                 {'loss': 0.4661, 'learning_rate': 0.00016539093719586994, 'epoch': 0.3}
 30%|██▉       | 139/469 [19:53<45:59,  8.36s/it] 30%|██▉       | 140/469 [20:02<45:41,  8.33s/it]                                                 {'loss': 0.4101, 'learning_rate': 0.0001648658419171666, 'epoch': 0.3}
 30%|██▉       | 140/469 [20:02<45:41,  8.33s/it] 30%|███       | 141/469 [20:10<45:18,  8.29s/it]                                                 {'loss': 0.4122, 'learning_rate': 0.00016433764063192194, 'epoch': 0.3}
 30%|███       | 141/469 [20:10<45:18,  8.29s/it] 30%|███       | 142/469 [20:18<44:52,  8.24s/it]                                                 {'loss': 0.3637, 'learning_rate': 0.0001638063586322866, 'epoch': 0.3}
 30%|███       | 142/469 [20:18<44:52,  8.24s/it] 30%|███       | 143/469 [20:26<45:02,  8.29s/it]                                                 {'loss': 0.3046, 'learning_rate': 0.00016327202135792685, 'epoch': 0.3}
 30%|███       | 143/469 [20:26<45:02,  8.29s/it] 31%|███       | 144/469 [20:35<45:28,  8.40s/it]                                                 {'loss': 0.4129, 'learning_rate': 0.00016273465439480618, 'epoch': 0.31}
 31%|███       | 144/469 [20:35<45:28,  8.40s/it] 31%|███       | 145/469 [20:44<45:29,  8.42s/it]                                                 {'loss': 0.3775, 'learning_rate': 0.00016219428347396053, 'epoch': 0.31}
 31%|███       | 145/469 [20:44<45:29,  8.42s/it] 31%|███       | 146/469 [20:52<45:02,  8.37s/it]                                                 {'loss': 0.3728, 'learning_rate': 0.0001616509344702658, 'epoch': 0.31}
 31%|███       | 146/469 [20:52<45:02,  8.37s/it] 31%|███▏      | 147/469 [21:00<44:29,  8.29s/it]                                                 {'loss': 0.3769, 'learning_rate': 0.00016110463340119913, 'epoch': 0.31}
 31%|███▏      | 147/469 [21:00<44:29,  8.29s/it] 32%|███▏      | 148/469 [21:08<44:07,  8.25s/it]                                                 {'loss': 0.3962, 'learning_rate': 0.00016055540642559305, 'epoch': 0.32}
 32%|███▏      | 148/469 [21:08<44:07,  8.25s/it] 32%|███▏      | 149/469 [21:17<44:21,  8.32s/it]                                                 {'loss': 0.3388, 'learning_rate': 0.00016000327984238292, 'epoch': 0.32}
 32%|███▏      | 149/469 [21:17<44:21,  8.32s/it] 32%|███▏      | 150/469 [21:25<44:39,  8.40s/it]                                                 {'loss': 0.3823, 'learning_rate': 0.0001594482800893474, 'epoch': 0.32}
 32%|███▏      | 150/469 [21:25<44:39,  8.40s/it] 32%|███▏      | 151/469 [21:34<44:48,  8.45s/it]                                                 {'loss': 0.3122, 'learning_rate': 0.00015889043374184286, 'epoch': 0.32}
 32%|███▏      | 151/469 [21:34<44:48,  8.45s/it] 32%|███▏      | 152/469 [21:42<44:19,  8.39s/it]                                                 {'loss': 0.3612, 'learning_rate': 0.00015832976751153078, 'epoch': 0.32}
 32%|███▏      | 152/469 [21:42<44:19,  8.39s/it] 33%|███▎      | 153/469 [21:50<43:55,  8.34s/it]                                                 {'loss': 0.3982, 'learning_rate': 0.0001577663082450984, 'epoch': 0.33}
 33%|███▎      | 153/469 [21:50<43:55,  8.34s/it] 33%|███▎      | 154/469 [21:58<43:36,  8.31s/it]                                                 {'loss': 0.3208, 'learning_rate': 0.00015720008292297364, 'epoch': 0.33}
 33%|███▎      | 154/469 [21:58<43:36,  8.31s/it] 33%|███▎      | 155/469 [22:07<43:58,  8.40s/it]                                                 {'loss': 0.3711, 'learning_rate': 0.00015663111865803285, 'epoch': 0.33}
 33%|███▎      | 155/469 [22:07<43:58,  8.40s/it] 33%|███▎      | 156/469 [22:16<44:07,  8.46s/it]                                                 {'loss': 0.3782, 'learning_rate': 0.00015605944269430277, 'epoch': 0.33}
 33%|███▎      | 156/469 [22:16<44:07,  8.46s/it] 33%|███▎      | 157/469 [22:24<44:04,  8.47s/it]                                                 {'loss': 0.3668, 'learning_rate': 0.00015548508240565583, 'epoch': 0.33}
 33%|███▎      | 157/469 [22:24<44:04,  8.47s/it] 34%|███▎      | 158/469 [22:33<44:15,  8.54s/it]                                                 {'loss': 0.3582, 'learning_rate': 0.00015490806529449945, 'epoch': 0.34}
 34%|███▎      | 158/469 [22:33<44:15,  8.54s/it] 34%|███▍      | 159/469 [22:41<43:53,  8.49s/it]                                                 {'loss': 0.3733, 'learning_rate': 0.0001543284189904592, 'epoch': 0.34}
 34%|███▍      | 159/469 [22:41<43:53,  8.49s/it] 34%|███▍      | 160/469 [22:49<43:19,  8.41s/it]                                                 {'loss': 0.3268, 'learning_rate': 0.00015374617124905564, 'epoch': 0.34}
 34%|███▍      | 160/469 [22:50<43:19,  8.41s/it] 34%|███▍      | 161/469 [22:58<42:42,  8.32s/it]                                                 {'loss': 0.3552, 'learning_rate': 0.00015316134995037545, 'epoch': 0.34}
 34%|███▍      | 161/469 [22:58<42:42,  8.32s/it] 35%|███▍      | 162/469 [23:06<42:52,  8.38s/it]                                                 {'loss': 0.3509, 'learning_rate': 0.00015257398309773633, 'epoch': 0.35}
 35%|███▍      | 162/469 [23:06<42:52,  8.38s/it] 35%|███▍      | 163/469 [23:15<42:59,  8.43s/it]                                                 {'loss': 0.4121, 'learning_rate': 0.00015198409881634617, 'epoch': 0.35}
 35%|███▍      | 163/469 [23:15<42:59,  8.43s/it] 35%|███▍      | 164/469 [23:23<42:38,  8.39s/it]                                                 {'loss': 0.3711, 'learning_rate': 0.00015139172535195617, 'epoch': 0.35}
 35%|███▍      | 164/469 [23:23<42:38,  8.39s/it] 35%|███▌      | 165/469 [23:31<42:08,  8.32s/it]                                                 {'loss': 0.3776, 'learning_rate': 0.00015079689106950854, 'epoch': 0.35}
 35%|███▌      | 165/469 [23:31<42:08,  8.32s/it] 35%|███▌      | 166/469 [23:39<41:48,  8.28s/it]                                                 {'loss': 0.3622, 'learning_rate': 0.00015019962445177819, 'epoch': 0.35}
 35%|███▌      | 166/469 [23:39<41:48,  8.28s/it] 36%|███▌      | 167/469 [23:47<41:25,  8.23s/it]                                                 {'loss': 0.3251, 'learning_rate': 0.00014959995409800873, 'epoch': 0.36}
 36%|███▌      | 167/469 [23:47<41:25,  8.23s/it] 36%|███▌      | 168/469 [23:56<41:44,  8.32s/it]                                                 {'loss': 0.3972, 'learning_rate': 0.0001489979087225434, 'epoch': 0.36}
 36%|███▌      | 168/469 [23:56<41:44,  8.32s/it] 36%|███▌      | 169/469 [24:04<41:52,  8.37s/it]                                                 {'loss': 0.3172, 'learning_rate': 0.00014839351715344968, 'epoch': 0.36}
 36%|███▌      | 169/469 [24:04<41:52,  8.37s/it] 36%|███▌      | 170/469 [24:13<41:26,  8.31s/it]                                                 {'loss': 0.3499, 'learning_rate': 0.00014778680833113926, 'epoch': 0.36}
 36%|███▌      | 170/469 [24:13<41:26,  8.31s/it] 36%|███▋      | 171/469 [24:21<41:24,  8.34s/it]                                                 {'loss': 0.3296, 'learning_rate': 0.00014717781130698212, 'epoch': 0.36}
 36%|███▋      | 171/469 [24:21<41:24,  8.34s/it] 37%|███▋      | 172/469 [24:29<41:30,  8.39s/it]                                                 {'loss': 0.3578, 'learning_rate': 0.00014656655524191537, 'epoch': 0.37}
 37%|███▋      | 172/469 [24:30<41:30,  8.39s/it] 37%|███▋      | 173/469 [24:38<41:08,  8.34s/it]                                                 {'loss': 0.3179, 'learning_rate': 0.00014595306940504716, 'epoch': 0.37}
 37%|███▋      | 173/469 [24:38<41:08,  8.34s/it] 37%|███▋      | 174/469 [24:46<41:05,  8.36s/it]                                                 {'loss': 0.3821, 'learning_rate': 0.00014533738317225485, 'epoch': 0.37}
 37%|███▋      | 174/469 [24:46<41:05,  8.36s/it] 37%|███▋      | 175/469 [24:55<41:18,  8.43s/it]                                                 {'loss': 0.3254, 'learning_rate': 0.00014471952602477866, 'epoch': 0.37}
 37%|███▋      | 175/469 [24:55<41:18,  8.43s/it] 38%|███▊      | 176/469 [25:03<41:13,  8.44s/it]                                                 {'loss': 0.3929, 'learning_rate': 0.0001440995275478099, 'epoch': 0.38}
 38%|███▊      | 176/469 [25:03<41:13,  8.44s/it] 38%|███▊      | 177/469 [25:11<40:36,  8.34s/it]                                                 {'loss': 0.3174, 'learning_rate': 0.00014347741742907433, 'epoch': 0.38}
 38%|███▊      | 177/469 [25:11<40:36,  8.34s/it] 38%|███▊      | 178/469 [25:19<40:12,  8.29s/it]                                                 {'loss': 0.3152, 'learning_rate': 0.00014285322545741052, 'epoch': 0.38}
 38%|███▊      | 178/469 [25:19<40:12,  8.29s/it] 38%|███▊      | 179/469 [25:28<40:20,  8.35s/it]                                                 {'loss': 0.3852, 'learning_rate': 0.00014222698152134374, 'epoch': 0.38}
 38%|███▊      | 179/469 [25:28<40:20,  8.35s/it] 38%|███▊      | 180/469 [25:36<40:16,  8.36s/it]                                                 {'loss': 0.3381, 'learning_rate': 0.00014159871560765432, 'epoch': 0.38}
 38%|███▊      | 180/469 [25:36<40:16,  8.36s/it] 39%|███▊      | 181/469 [25:45<40:17,  8.39s/it]                                                 {'loss': 0.3264, 'learning_rate': 0.0001409684577999423, 'epoch': 0.39}
 39%|███▊      | 181/469 [25:45<40:17,  8.39s/it] 39%|███▉      | 182/469 [25:53<40:11,  8.40s/it]                                                 {'loss': 0.3774, 'learning_rate': 0.0001403362382771865, 'epoch': 0.39}
 39%|███▉      | 182/469 [25:53<40:11,  8.40s/it] 39%|███▉      | 183/469 [26:01<39:49,  8.36s/it]                                                 {'loss': 0.357, 'learning_rate': 0.00013970208731229974, 'epoch': 0.39}
 39%|███▉      | 183/469 [26:01<39:49,  8.36s/it] 39%|███▉      | 184/469 [26:10<39:24,  8.30s/it]                                                 {'loss': 0.3449, 'learning_rate': 0.000139066035270679, 'epoch': 0.39}
 39%|███▉      | 184/469 [26:10<39:24,  8.30s/it] 39%|███▉      | 185/469 [26:18<38:58,  8.23s/it]                                                 {'loss': 0.3574, 'learning_rate': 0.00013842811260875168, 'epoch': 0.39}
 39%|███▉      | 185/469 [26:18<38:58,  8.23s/it] 40%|███▉      | 186/469 [26:26<39:05,  8.29s/it]                                                 {'loss': 0.3818, 'learning_rate': 0.00013778834987251707, 'epoch': 0.4}
 40%|███▉      | 186/469 [26:26<39:05,  8.29s/it] 40%|███▉      | 187/469 [26:35<39:28,  8.40s/it]                                                 {'loss': 0.3657, 'learning_rate': 0.0001371467776960837, 'epoch': 0.4}
 40%|███▉      | 187/469 [26:35<39:28,  8.40s/it] 40%|████      | 188/469 [26:43<39:25,  8.42s/it]                                                 {'loss': 0.3387, 'learning_rate': 0.00013650342680020258, 'epoch': 0.4}
 40%|████      | 188/469 [26:43<39:25,  8.42s/it] 40%|████      | 189/469 [26:52<39:11,  8.40s/it]                                                 {'loss': 0.2919, 'learning_rate': 0.0001358583279907961, 'epoch': 0.4}
 40%|████      | 189/469 [26:52<39:11,  8.40s/it] 41%|████      | 190/469 [27:00<38:29,  8.28s/it]                                                 {'loss': 0.2511, 'learning_rate': 0.0001352115121574829, 'epoch': 0.41}
 41%|████      | 190/469 [27:00<38:29,  8.28s/it] 41%|████      | 191/469 [27:08<38:10,  8.24s/it]                                                 {'loss': 0.3038, 'learning_rate': 0.00013456301027209882, 'epoch': 0.41}
 41%|████      | 191/469 [27:08<38:10,  8.24s/it] 41%|████      | 192/469 [27:16<38:21,  8.31s/it]                                                 {'loss': 0.316, 'learning_rate': 0.000133912853387214, 'epoch': 0.41}
 41%|████      | 192/469 [27:16<38:21,  8.31s/it] 41%|████      | 193/469 [27:25<38:37,  8.40s/it]                                                 {'loss': 0.3691, 'learning_rate': 0.00013326107263464558, 'epoch': 0.41}
 41%|████      | 193/469 [27:25<38:37,  8.40s/it] 41%|████▏     | 194/469 [27:33<38:24,  8.38s/it]                                                 {'loss': 0.3892, 'learning_rate': 0.0001326076992239674, 'epoch': 0.41}
 41%|████▏     | 194/469 [27:33<38:24,  8.38s/it] 42%|████▏     | 195/469 [27:41<38:03,  8.33s/it]                                                 {'loss': 0.3168, 'learning_rate': 0.00013195276444101547, 'epoch': 0.42}
 42%|████▏     | 195/469 [27:41<38:03,  8.33s/it] 42%|████▏     | 196/469 [27:50<38:06,  8.37s/it]                                                 {'loss': 0.3634, 'learning_rate': 0.0001312962996463896, 'epoch': 0.42}
 42%|████▏     | 196/469 [27:50<38:06,  8.37s/it] 42%|████▏     | 197/469 [27:58<37:43,  8.32s/it]                                                 {'loss': 0.3197, 'learning_rate': 0.0001306383362739523, 'epoch': 0.42}
 42%|████▏     | 197/469 [27:58<37:43,  8.32s/it] 42%|████▏     | 198/469 [28:06<37:44,  8.35s/it]                                                 {'loss': 0.3787, 'learning_rate': 0.00012997890582932303, 'epoch': 0.42}
 42%|████▏     | 198/469 [28:06<37:44,  8.35s/it] 42%|████▏     | 199/469 [28:15<38:02,  8.45s/it]                                                 {'loss': 0.3928, 'learning_rate': 0.0001293180398883701, 'epoch': 0.42}
 42%|████▏     | 199/469 [28:15<38:02,  8.45s/it] 43%|████▎     | 200/469 [28:24<37:57,  8.47s/it]                                                 {'loss': 0.3718, 'learning_rate': 0.00012865577009569824, 'epoch': 0.43}
 43%|████▎     | 200/469 [28:24<37:57,  8.47s/it] 43%|████▎     | 201/469 [28:32<37:39,  8.43s/it]                                                 {'loss': 0.3555, 'learning_rate': 0.00012799212816313376, 'epoch': 0.43}
 43%|████▎     | 201/469 [28:32<37:39,  8.43s/it] 43%|████▎     | 202/469 [28:40<37:22,  8.40s/it]                                                 {'loss': 0.3697, 'learning_rate': 0.00012732714586820583, 'epoch': 0.43}
 43%|████▎     | 202/469 [28:40<37:22,  8.40s/it] 43%|████▎     | 203/469 [28:49<37:11,  8.39s/it]                                                 {'loss': 0.3736, 'learning_rate': 0.00012666085505262485, 'epoch': 0.43}
 43%|████▎     | 203/469 [28:49<37:11,  8.39s/it] 43%|████▎     | 204/469 [28:57<36:59,  8.38s/it]                                                 {'loss': 0.3823, 'learning_rate': 0.000125993287620758, 'epoch': 0.43}
 43%|████▎     | 204/469 [28:57<36:59,  8.38s/it] 44%|████▎     | 205/469 [29:06<37:10,  8.45s/it]                                                 {'loss': 0.3662, 'learning_rate': 0.00012532447553810126, 'epoch': 0.44}
 44%|████▎     | 205/469 [29:06<37:10,  8.45s/it] 44%|████▍     | 206/469 [29:14<37:10,  8.48s/it]                                                 {'loss': 0.3636, 'learning_rate': 0.00012465445082974886, 'epoch': 0.44}
 44%|████▍     | 206/469 [29:14<37:10,  8.48s/it] 44%|████▍     | 207/469 [29:22<36:44,  8.41s/it]                                                 {'loss': 0.359, 'learning_rate': 0.00012398324557885994, 'epoch': 0.44}
 44%|████▍     | 207/469 [29:23<36:44,  8.41s/it] 44%|████▍     | 208/469 [29:31<36:26,  8.38s/it]                                                 {'loss': 0.3922, 'learning_rate': 0.00012331089192512218, 'epoch': 0.44}
 44%|████▍     | 208/469 [29:31<36:26,  8.38s/it] 45%|████▍     | 209/469 [29:39<36:30,  8.43s/it]                                                 {'loss': 0.3935, 'learning_rate': 0.00012263742206321287, 'epoch': 0.45}
 45%|████▍     | 209/469 [29:39<36:30,  8.43s/it] 45%|████▍     | 210/469 [29:48<36:23,  8.43s/it]                                                 {'loss': 0.3955, 'learning_rate': 0.00012196286824125726, 'epoch': 0.45}
 45%|████▍     | 210/469 [29:48<36:23,  8.43s/it] 45%|████▍     | 211/469 [29:56<36:21,  8.46s/it]                                                 {'loss': 0.3397, 'learning_rate': 0.0001212872627592845, 'epoch': 0.45}
 45%|████▍     | 211/469 [29:56<36:21,  8.46s/it] 45%|████▌     | 212/469 [30:05<36:27,  8.51s/it]                                                 {'loss': 0.3813, 'learning_rate': 0.0001206106379676809, 'epoch': 0.45}
 45%|████▌     | 212/469 [30:05<36:27,  8.51s/it] 45%|████▌     | 213/469 [30:13<36:12,  8.49s/it]                                                 {'loss': 0.3027, 'learning_rate': 0.00011993302626564102, 'epoch': 0.45}
 45%|████▌     | 213/469 [30:13<36:12,  8.49s/it] 46%|████▌     | 214/469 [30:22<35:56,  8.46s/it]                                                 {'loss': 0.3823, 'learning_rate': 0.00011925446009961607, 'epoch': 0.46}
 46%|████▌     | 214/469 [30:22<35:56,  8.46s/it] 46%|████▌     | 215/469 [30:30<35:40,  8.43s/it]                                                 {'loss': 0.3936, 'learning_rate': 0.00011857497196176049, 'epoch': 0.46}
 46%|████▌     | 215/469 [30:30<35:40,  8.43s/it] 46%|████▌     | 216/469 [30:38<35:14,  8.36s/it]                                                 {'loss': 0.2965, 'learning_rate': 0.00011789459438837589, 'epoch': 0.46}
 46%|████▌     | 216/469 [30:38<35:14,  8.36s/it] 46%|████▋     | 217/469 [30:47<35:06,  8.36s/it]                                                 {'loss': 0.3973, 'learning_rate': 0.00011721335995835336, 'epoch': 0.46}
 46%|████▋     | 217/469 [30:47<35:06,  8.36s/it] 46%|████▋     | 218/469 [30:56<35:42,  8.53s/it]                                                 {'loss': 0.3467, 'learning_rate': 0.00011653130129161316, 'epoch': 0.46}
 46%|████▋     | 218/469 [30:56<35:42,  8.53s/it] 47%|████▋     | 219/469 [31:04<35:41,  8.57s/it]                                                 {'loss': 0.3137, 'learning_rate': 0.00011584845104754304, 'epoch': 0.47}
 47%|████▋     | 219/469 [31:04<35:41,  8.57s/it] 47%|████▋     | 220/469 [31:14<37:01,  8.92s/it]                                                 {'loss': 0.3276, 'learning_rate': 0.00011516484192343425, 'epoch': 0.47}
 47%|████▋     | 220/469 [31:14<37:01,  8.92s/it] 47%|████▋     | 221/469 [31:22<36:04,  8.73s/it]                                                 {'loss': 0.3465, 'learning_rate': 0.00011448050665291587, 'epoch': 0.47}
 47%|████▋     | 221/469 [31:22<36:04,  8.73s/it] 47%|████▋     | 222/469 [31:31<35:33,  8.64s/it]                                                 {'loss': 0.3543, 'learning_rate': 0.00011379547800438747, 'epoch': 0.47}
 47%|████▋     | 222/469 [31:31<35:33,  8.64s/it] 48%|████▊     | 223/469 [31:39<35:27,  8.65s/it]                                                 {'loss': 0.3685, 'learning_rate': 0.00011310978877945007, 'epoch': 0.48}
 48%|████▊     | 223/469 [31:39<35:27,  8.65s/it] 48%|████▊     | 224/469 [31:48<35:06,  8.60s/it]                                                 {'loss': 0.3981, 'learning_rate': 0.00011242347181133533, 'epoch': 0.48}
 48%|████▊     | 224/469 [31:48<35:06,  8.60s/it] 48%|████▊     | 225/469 [31:56<34:53,  8.58s/it]                                                 {'loss': 0.3508, 'learning_rate': 0.00011173655996333357, 'epoch': 0.48}
 48%|████▊     | 225/469 [31:56<34:53,  8.58s/it] 48%|████▊     | 226/469 [32:05<34:46,  8.59s/it]                                                 {'loss': 0.2933, 'learning_rate': 0.00011104908612722001, 'epoch': 0.48}
 48%|████▊     | 226/469 [32:05<34:46,  8.59s/it] 48%|████▊     | 227/469 [32:14<34:38,  8.59s/it]                                                 {'loss': 0.3761, 'learning_rate': 0.00011036108322167988, 'epoch': 0.48}
 48%|████▊     | 227/469 [32:14<34:38,  8.59s/it] 49%|████▊     | 228/469 [32:22<34:29,  8.59s/it]                                                 {'loss': 0.3277, 'learning_rate': 0.00010967258419073217, 'epoch': 0.49}
 49%|████▊     | 228/469 [32:22<34:29,  8.59s/it] 49%|████▉     | 229/469 [32:31<34:40,  8.67s/it]                                                 {'loss': 0.2787, 'learning_rate': 0.00010898362200215197, 'epoch': 0.49}
 49%|████▉     | 229/469 [32:31<34:40,  8.67s/it] 49%|████▉     | 230/469 [32:41<35:52,  9.00s/it]                                                 {'loss': 0.3596, 'learning_rate': 0.0001082942296458922, 'epoch': 0.49}
 49%|████▉     | 230/469 [32:41<35:52,  9.00s/it] 49%|████▉     | 231/469 [32:51<36:52,  9.29s/it]                                                 {'loss': 0.3919, 'learning_rate': 0.0001076044401325036, 'epoch': 0.49}
 49%|████▉     | 231/469 [32:51<36:52,  9.29s/it] 49%|████▉     | 232/469 [33:00<36:30,  9.24s/it]                                                 {'loss': 0.2859, 'learning_rate': 0.0001069142864915542, 'epoch': 0.49}
 49%|████▉     | 232/469 [33:00<36:30,  9.24s/it] 50%|████▉     | 233/469 [33:09<36:08,  9.19s/it]                                                 {'loss': 0.3596, 'learning_rate': 0.0001062238017700478, 'epoch': 0.5}
 50%|████▉     | 233/469 [33:09<36:08,  9.19s/it] 50%|████▉     | 234/469 [33:18<36:00,  9.19s/it]                                                 {'loss': 0.3851, 'learning_rate': 0.00010553301903084157, 'epoch': 0.5}
 50%|████▉     | 234/469 [33:18<36:00,  9.19s/it] 50%|█████     | 235/469 [33:26<34:51,  8.94s/it]                                                 {'loss': 0.3231, 'learning_rate': 0.00010484197135106263, 'epoch': 0.5}
 50%|█████     | 235/469 [33:27<34:51,  8.94s/it] 50%|█████     | 236/469 [33:35<34:25,  8.87s/it]                                                 {'loss': 0.363, 'learning_rate': 0.0001041506918205246, 'epoch': 0.5}
 50%|█████     | 236/469 [33:35<34:25,  8.87s/it] 51%|█████     | 237/469 [33:44<33:50,  8.75s/it]                                                 {'loss': 0.3542, 'learning_rate': 0.00010345921354014279, 'epoch': 0.51}
 51%|█████     | 237/469 [33:44<33:50,  8.75s/it] 51%|█████     | 238/469 [33:52<33:12,  8.63s/it]                                                 {'loss': 0.333, 'learning_rate': 0.0001027675696203495, 'epoch': 0.51}
 51%|█████     | 238/469 [33:52<33:12,  8.63s/it] 51%|█████     | 239/469 [34:00<32:34,  8.50s/it]                                                 {'loss': 0.3555, 'learning_rate': 0.00010207579317950827, 'epoch': 0.51}
 51%|█████     | 239/469 [34:00<32:34,  8.50s/it] 51%|█████     | 240/469 [34:09<32:33,  8.53s/it]                                                 {'loss': 0.3356, 'learning_rate': 0.00010138391734232832, 'epoch': 0.51}
 51%|█████     | 240/469 [34:09<32:33,  8.53s/it] 51%|█████▏    | 241/469 [34:17<32:08,  8.46s/it]                                                 {'loss': 0.3266, 'learning_rate': 0.00010069197523827833, 'epoch': 0.51}
 51%|█████▏    | 241/469 [34:17<32:08,  8.46s/it] 52%|█████▏    | 242/469 [34:26<32:21,  8.55s/it]                                                 {'loss': 0.3217, 'learning_rate': 0.0001, 'epoch': 0.52}
 52%|█████▏    | 242/469 [34:26<32:21,  8.55s/it] 52%|█████▏    | 243/469 [34:35<32:23,  8.60s/it]                                                 {'loss': 0.361, 'learning_rate': 9.930802476172169e-05, 'epoch': 0.52}
 52%|█████▏    | 243/469 [34:35<32:23,  8.60s/it] 52%|█████▏    | 244/469 [34:43<31:57,  8.52s/it]                                                 {'loss': 0.3401, 'learning_rate': 9.861608265767167e-05, 'epoch': 0.52}
 52%|█████▏    | 244/469 [34:43<31:57,  8.52s/it] 52%|█████▏    | 245/469 [34:51<31:46,  8.51s/it]                                                 {'loss': 0.3375, 'learning_rate': 9.792420682049174e-05, 'epoch': 0.52}
 52%|█████▏    | 245/469 [34:51<31:46,  8.51s/it] 52%|█████▏    | 246/469 [35:00<31:15,  8.41s/it]                                                 {'loss': 0.3132, 'learning_rate': 9.723243037965056e-05, 'epoch': 0.52}
 52%|█████▏    | 246/469 [35:00<31:15,  8.41s/it] 53%|█████▎    | 247/469 [35:08<31:41,  8.56s/it]                                                 {'loss': 0.2948, 'learning_rate': 9.654078645985722e-05, 'epoch': 0.53}
 53%|█████▎    | 247/469 [35:09<31:41,  8.56s/it] 53%|█████▎    | 248/469 [35:17<31:22,  8.52s/it]                                                 {'loss': 0.3619, 'learning_rate': 9.584930817947544e-05, 'epoch': 0.53}
 53%|█████▎    | 248/469 [35:17<31:22,  8.52s/it] 53%|█████▎    | 249/469 [35:25<31:10,  8.50s/it]                                                 {'loss': 0.2162, 'learning_rate': 9.515802864893739e-05, 'epoch': 0.53}
 53%|█████▎    | 249/469 [35:25<31:10,  8.50s/it] 53%|█████▎    | 250/469 [35:34<31:04,  8.51s/it]                                                 {'loss': 0.3406, 'learning_rate': 9.446698096915847e-05, 'epoch': 0.53}
 53%|█████▎    | 250/469 [35:34<31:04,  8.51s/it] 54%|█████▎    | 251/469 [35:42<30:51,  8.49s/it]                                                 {'loss': 0.3846, 'learning_rate': 9.377619822995219e-05, 'epoch': 0.54}
 54%|█████▎    | 251/469 [35:42<30:51,  8.49s/it] 54%|█████▎    | 252/469 [35:51<30:33,  8.45s/it]                                                 {'loss': 0.3509, 'learning_rate': 9.308571350844584e-05, 'epoch': 0.54}
 54%|█████▎    | 252/469 [35:51<30:33,  8.45s/it] 54%|█████▍    | 253/469 [35:59<30:06,  8.37s/it]                                                 {'loss': 0.3152, 'learning_rate': 9.239555986749645e-05, 'epoch': 0.54}
 54%|█████▍    | 253/469 [35:59<30:06,  8.37s/it] 54%|█████▍    | 254/469 [36:07<29:51,  8.33s/it]                                                 {'loss': 0.3009, 'learning_rate': 9.170577035410783e-05, 'epoch': 0.54}
 54%|█████▍    | 254/469 [36:07<29:51,  8.33s/it] 54%|█████▍    | 255/469 [36:16<30:04,  8.43s/it]                                                 {'loss': 0.3664, 'learning_rate': 9.101637799784804e-05, 'epoch': 0.54}
 54%|█████▍    | 255/469 [36:16<30:04,  8.43s/it] 55%|█████▍    | 256/469 [36:25<30:15,  8.53s/it]                                                 {'loss': 0.3792, 'learning_rate': 9.032741580926787e-05, 'epoch': 0.55}
 55%|█████▍    | 256/469 [36:25<30:15,  8.53s/it] 55%|█████▍    | 257/469 [36:33<29:57,  8.48s/it]                                                 {'loss': 0.3155, 'learning_rate': 8.963891677832011e-05, 'epoch': 0.55}
 55%|█████▍    | 257/469 [36:33<29:57,  8.48s/it] 55%|█████▌    | 258/469 [36:41<29:31,  8.40s/it]                                                 {'loss': 0.3206, 'learning_rate': 8.895091387277999e-05, 'epoch': 0.55}
 55%|█████▌    | 258/469 [36:41<29:31,  8.40s/it] 55%|█████▌    | 259/469 [36:49<29:19,  8.38s/it]                                                 {'loss': 0.2913, 'learning_rate': 8.826344003666647e-05, 'epoch': 0.55}
 55%|█████▌    | 259/469 [36:49<29:19,  8.38s/it] 55%|█████▌    | 260/469 [36:58<29:02,  8.34s/it]                                                 {'loss': 0.3064, 'learning_rate': 8.757652818866471e-05, 'epoch': 0.55}
 55%|█████▌    | 260/469 [36:58<29:02,  8.34s/it] 56%|█████▌    | 261/469 [37:06<29:05,  8.39s/it]                                                 {'loss': 0.327, 'learning_rate': 8.689021122054996e-05, 'epoch': 0.56}
 56%|█████▌    | 261/469 [37:06<29:05,  8.39s/it] 56%|█████▌    | 262/469 [37:15<29:16,  8.49s/it]                                                 {'loss': 0.4347, 'learning_rate': 8.620452199561254e-05, 'epoch': 0.56}
 56%|█████▌    | 262/469 [37:15<29:16,  8.49s/it] 56%|█████▌    | 263/469 [37:23<29:09,  8.49s/it]                                                 {'loss': 0.3309, 'learning_rate': 8.551949334708415e-05, 'epoch': 0.56}
 56%|█████▌    | 263/469 [37:23<29:09,  8.49s/it] 56%|█████▋    | 264/469 [37:32<28:49,  8.44s/it]                                                 {'loss': 0.3046, 'learning_rate': 8.483515807656576e-05, 'epoch': 0.56}
 56%|█████▋    | 264/469 [37:32<28:49,  8.44s/it] 57%|█████▋    | 265/469 [37:40<28:40,  8.44s/it]                                                 {'loss': 0.3474, 'learning_rate': 8.415154895245697e-05, 'epoch': 0.57}
 57%|█████▋    | 265/469 [37:40<28:40,  8.44s/it] 57%|█████▋    | 266/469 [37:48<28:25,  8.40s/it]                                                 {'loss': 0.3844, 'learning_rate': 8.346869870838685e-05, 'epoch': 0.57}
 57%|█████▋    | 266/469 [37:49<28:25,  8.40s/it] 57%|█████▋    | 267/469 [37:57<28:11,  8.37s/it]                                                 {'loss': 0.3709, 'learning_rate': 8.278664004164665e-05, 'epoch': 0.57}
 57%|█████▋    | 267/469 [37:57<28:11,  8.37s/it] 57%|█████▋    | 268/469 [38:05<28:19,  8.46s/it]                                                 {'loss': 0.3451, 'learning_rate': 8.210540561162412e-05, 'epoch': 0.57}
 57%|█████▋    | 268/469 [38:06<28:19,  8.46s/it] 57%|█████▋    | 269/469 [38:14<28:29,  8.55s/it]                                                 {'loss': 0.318, 'learning_rate': 8.142502803823955e-05, 'epoch': 0.57}
 57%|█████▋    | 269/469 [38:14<28:29,  8.55s/it] 58%|█████▊    | 270/469 [38:23<28:08,  8.48s/it]                                                 {'loss': 0.3343, 'learning_rate': 8.074553990038395e-05, 'epoch': 0.58}
 58%|█████▊    | 270/469 [38:23<28:08,  8.48s/it] 58%|█████▊    | 271/469 [38:31<27:57,  8.47s/it]                                                 {'loss': 0.3067, 'learning_rate': 8.0066973734359e-05, 'epoch': 0.58}
 58%|█████▊    | 271/469 [38:31<27:57,  8.47s/it] 58%|█████▊    | 272/469 [38:39<27:38,  8.42s/it]                                                 {'loss': 0.3561, 'learning_rate': 7.938936203231912e-05, 'epoch': 0.58}
 58%|█████▊    | 272/469 [38:39<27:38,  8.42s/it] 58%|█████▊    | 273/469 [38:48<27:25,  8.40s/it]                                                 {'loss': 0.3519, 'learning_rate': 7.871273724071553e-05, 'epoch': 0.58}
 58%|█████▊    | 273/469 [38:48<27:25,  8.40s/it] 58%|█████▊    | 274/469 [38:56<27:27,  8.45s/it]                                                 {'loss': 0.3578, 'learning_rate': 7.803713175874275e-05, 'epoch': 0.58}
 58%|█████▊    | 274/469 [38:56<27:27,  8.45s/it] 59%|█████▊    | 275/469 [39:05<27:32,  8.52s/it]                                                 {'loss': 0.3216, 'learning_rate': 7.736257793678714e-05, 'epoch': 0.59}
 59%|█████▊    | 275/469 [39:05<27:32,  8.52s/it] 59%|█████▉    | 276/469 [39:13<27:17,  8.49s/it]                                                 {'loss': 0.3776, 'learning_rate': 7.668910807487783e-05, 'epoch': 0.59}
 59%|█████▉    | 276/469 [39:13<27:17,  8.49s/it] 59%|█████▉    | 277/469 [39:22<26:59,  8.44s/it]                                                 {'loss': 0.2947, 'learning_rate': 7.601675442114009e-05, 'epoch': 0.59}
 59%|█████▉    | 277/469 [39:22<26:59,  8.44s/it] 59%|█████▉    | 278/469 [39:30<26:33,  8.34s/it]                                                 {'loss': 0.3329, 'learning_rate': 7.534554917025119e-05, 'epoch': 0.59}
 59%|█████▉    | 278/469 [39:30<26:33,  8.34s/it] 59%|█████▉    | 279/469 [39:38<26:18,  8.31s/it]                                                 {'loss': 0.36, 'learning_rate': 7.46755244618988e-05, 'epoch': 0.59}
 59%|█████▉    | 279/469 [39:38<26:18,  8.31s/it] 60%|█████▉    | 280/469 [39:46<26:17,  8.35s/it]                                                 {'loss': 0.3485, 'learning_rate': 7.400671237924202e-05, 'epoch': 0.6}
 60%|█████▉    | 280/469 [39:46<26:17,  8.35s/it] 60%|█████▉    | 281/469 [39:55<26:18,  8.40s/it]                                                 {'loss': 0.3049, 'learning_rate': 7.333914494737514e-05, 'epoch': 0.6}
 60%|█████▉    | 281/469 [39:55<26:18,  8.40s/it] 60%|██████    | 282/469 [40:03<26:18,  8.44s/it]                                                 {'loss': 0.3954, 'learning_rate': 7.267285413179421e-05, 'epoch': 0.6}
 60%|██████    | 282/469 [40:04<26:18,  8.44s/it] 60%|██████    | 283/469 [40:12<26:04,  8.41s/it]                                                 {'loss': 0.3104, 'learning_rate': 7.200787183686625e-05, 'epoch': 0.6}
 60%|██████    | 283/469 [40:12<26:04,  8.41s/it] 61%|██████    | 284/469 [40:20<26:00,  8.43s/it]                                                 {'loss': 0.337, 'learning_rate': 7.134422990430176e-05, 'epoch': 0.61}
 61%|██████    | 284/469 [40:20<26:00,  8.43s/it] 61%|██████    | 285/469 [40:29<25:51,  8.43s/it]                                                 {'loss': 0.32, 'learning_rate': 7.068196011162994e-05, 'epoch': 0.61}
 61%|██████    | 285/469 [40:29<25:51,  8.43s/it] 61%|██████    | 286/469 [40:37<25:41,  8.42s/it]                                                 {'loss': 0.3681, 'learning_rate': 7.002109417067697e-05, 'epoch': 0.61}
 61%|██████    | 286/469 [40:37<25:41,  8.42s/it] 61%|██████    | 287/469 [40:46<25:44,  8.49s/it]                                                 {'loss': 0.3227, 'learning_rate': 6.936166372604773e-05, 'epoch': 0.61}
 61%|██████    | 287/469 [40:46<25:44,  8.49s/it] 61%|██████▏   | 288/469 [40:54<25:45,  8.54s/it]                                                 {'loss': 0.3664, 'learning_rate': 6.87037003536104e-05, 'epoch': 0.61}
 61%|██████▏   | 288/469 [40:55<25:45,  8.54s/it] 62%|██████▏   | 289/469 [41:03<25:25,  8.47s/it]                                                 {'loss': 0.313, 'learning_rate': 6.804723555898458e-05, 'epoch': 0.62}
 62%|██████▏   | 289/469 [41:03<25:25,  8.47s/it] 62%|██████▏   | 290/469 [41:11<25:05,  8.41s/it]                                                 {'loss': 0.3356, 'learning_rate': 6.739230077603259e-05, 'epoch': 0.62}
 62%|██████▏   | 290/469 [41:11<25:05,  8.41s/it] 62%|██████▏   | 291/469 [41:19<24:54,  8.40s/it]                                                 {'loss': 0.3657, 'learning_rate': 6.673892736535448e-05, 'epoch': 0.62}
 62%|██████▏   | 291/469 [41:19<24:54,  8.40s/it] 62%|██████▏   | 292/469 [41:28<24:39,  8.36s/it]                                                 {'loss': 0.358, 'learning_rate': 6.608714661278606e-05, 'epoch': 0.62}
 62%|██████▏   | 292/469 [41:28<24:39,  8.36s/it] 62%|██████▏   | 293/469 [41:36<24:36,  8.39s/it]                                                 {'loss': 0.314, 'learning_rate': 6.543698972790117e-05, 'epoch': 0.62}
 62%|██████▏   | 293/469 [41:36<24:36,  8.39s/it] 63%|██████▎   | 294/469 [41:45<24:38,  8.45s/it]                                                 {'loss': 0.3491, 'learning_rate': 6.478848784251713e-05, 'epoch': 0.63}
 63%|██████▎   | 294/469 [41:45<24:38,  8.45s/it] 63%|██████▎   | 295/469 [41:53<24:25,  8.42s/it]                                                 {'loss': 0.3893, 'learning_rate': 6.414167200920391e-05, 'epoch': 0.63}
 63%|██████▎   | 295/469 [41:53<24:25,  8.42s/it] 63%|██████▎   | 296/469 [42:01<24:14,  8.41s/it]                                                 {'loss': 0.4068, 'learning_rate': 6.349657319979742e-05, 'epoch': 0.63}
 63%|██████▎   | 296/469 [42:01<24:14,  8.41s/it] 63%|██████▎   | 297/469 [42:10<24:01,  8.38s/it]                                                 {'loss': 0.3662, 'learning_rate': 6.28532223039163e-05, 'epoch': 0.63}
 63%|██████▎   | 297/469 [42:10<24:01,  8.38s/it] 64%|██████▎   | 298/469 [42:18<23:48,  8.35s/it]                                                 {'loss': 0.3509, 'learning_rate': 6.221165012748297e-05, 'epoch': 0.64}
 64%|██████▎   | 298/469 [42:18<23:48,  8.35s/it] 64%|██████▍   | 299/469 [42:26<23:43,  8.37s/it]                                                 {'loss': 0.3781, 'learning_rate': 6.157188739124834e-05, 'epoch': 0.64}
 64%|██████▍   | 299/469 [42:26<23:43,  8.37s/it] 64%|██████▍   | 300/469 [42:35<23:52,  8.47s/it]                                                 {'loss': 0.3365, 'learning_rate': 6.093396472932103e-05, 'epoch': 0.64}
 64%|██████▍   | 300/469 [42:35<23:52,  8.47s/it] 64%|██████▍   | 301/469 [42:44<23:46,  8.49s/it]                                                 {'loss': 0.3014, 'learning_rate': 6.029791268770029e-05, 'epoch': 0.64}
 64%|██████▍   | 301/469 [42:44<23:46,  8.49s/it] 64%|██████▍   | 302/469 [42:52<23:27,  8.43s/it]                                                 {'loss': 0.3156, 'learning_rate': 5.9663761722813495e-05, 'epoch': 0.64}
 64%|██████▍   | 302/469 [42:52<23:27,  8.43s/it] 65%|██████▍   | 303/469 [43:00<23:12,  8.39s/it]                                                 {'loss': 0.3614, 'learning_rate': 5.903154220005771e-05, 'epoch': 0.65}
 65%|██████▍   | 303/469 [43:00<23:12,  8.39s/it] 65%|██████▍   | 304/469 [43:09<23:03,  8.38s/it]                                                 {'loss': 0.3015, 'learning_rate': 5.840128439234571e-05, 'epoch': 0.65}
 65%|██████▍   | 304/469 [43:09<23:03,  8.38s/it] 65%|██████▌   | 305/469 [43:17<22:50,  8.36s/it]                                                 {'loss': 0.3978, 'learning_rate': 5.777301847865629e-05, 'epoch': 0.65}
 65%|██████▌   | 305/469 [43:17<22:50,  8.36s/it] 65%|██████▌   | 306/469 [43:26<22:56,  8.44s/it]                                                 {'loss': 0.3024, 'learning_rate': 5.714677454258947e-05, 'epoch': 0.65}
 65%|██████▌   | 306/469 [43:26<22:56,  8.44s/it] 65%|██████▌   | 307/469 [43:34<23:03,  8.54s/it]                                                 {'loss': 0.3641, 'learning_rate': 5.652258257092569e-05, 'epoch': 0.65}
 65%|██████▌   | 307/469 [43:34<23:03,  8.54s/it] 66%|██████▌   | 308/469 [43:43<22:46,  8.49s/it]                                                 {'loss': 0.3537, 'learning_rate': 5.590047245219009e-05, 'epoch': 0.66}
 66%|██████▌   | 308/469 [43:43<22:46,  8.49s/it] 66%|██████▌   | 309/469 [43:51<22:20,  8.38s/it]                                                 {'loss': 0.3124, 'learning_rate': 5.528047397522133e-05, 'epoch': 0.66}
 66%|██████▌   | 309/469 [43:51<22:20,  8.38s/it] 66%|██████▌   | 310/469 [43:59<22:08,  8.36s/it]                                                 {'loss': 0.2843, 'learning_rate': 5.4662616827745185e-05, 'epoch': 0.66}
 66%|██████▌   | 310/469 [43:59<22:08,  8.36s/it] 66%|██████▋   | 311/469 [44:07<21:49,  8.29s/it]                                                 {'loss': 0.3094, 'learning_rate': 5.404693059495285e-05, 'epoch': 0.66}
 66%|██████▋   | 311/469 [44:07<21:49,  8.29s/it] 67%|██████▋   | 312/469 [44:16<21:58,  8.40s/it]                                                 {'loss': 0.2905, 'learning_rate': 5.3433444758084604e-05, 'epoch': 0.67}
 67%|██████▋   | 312/469 [44:16<21:58,  8.40s/it] 67%|██████▋   | 313/469 [44:24<21:56,  8.44s/it]                                                 {'loss': 0.3542, 'learning_rate': 5.282218869301788e-05, 'epoch': 0.67}
 67%|██████▋   | 313/469 [44:24<21:56,  8.44s/it] 67%|██████▋   | 314/469 [44:33<21:46,  8.43s/it]                                                 {'loss': 0.3108, 'learning_rate': 5.221319166886073e-05, 'epoch': 0.67}
 67%|██████▋   | 314/469 [44:33<21:46,  8.43s/it] 67%|██████▋   | 315/469 [44:41<21:40,  8.45s/it]                                                 {'loss': 0.3519, 'learning_rate': 5.160648284655032e-05, 'epoch': 0.67}
 67%|██████▋   | 315/469 [44:41<21:40,  8.45s/it] 67%|██████▋   | 316/469 [44:50<21:28,  8.42s/it]                                                 {'loss': 0.3634, 'learning_rate': 5.100209127745661e-05, 'epoch': 0.67}
 67%|██████▋   | 316/469 [44:50<21:28,  8.42s/it] 68%|██████▊   | 317/469 [44:58<21:10,  8.36s/it]                                                 {'loss': 0.366, 'learning_rate': 5.040004590199128e-05, 'epoch': 0.68}
 68%|██████▊   | 317/469 [44:58<21:10,  8.36s/it] 68%|██████▊   | 318/469 [45:06<21:06,  8.39s/it]                                                 {'loss': 0.3022, 'learning_rate': 4.9800375548221845e-05, 'epoch': 0.68}
 68%|██████▊   | 318/469 [45:06<21:06,  8.39s/it] 68%|██████▊   | 319/469 [45:15<21:08,  8.46s/it]                                                 {'loss': 0.3561, 'learning_rate': 4.920310893049146e-05, 'epoch': 0.68}
 68%|██████▊   | 319/469 [45:15<21:08,  8.46s/it] 68%|██████▊   | 320/469 [45:23<20:51,  8.40s/it]                                                 {'loss': 0.3946, 'learning_rate': 4.860827464804383e-05, 'epoch': 0.68}
 68%|██████▊   | 320/469 [45:23<20:51,  8.40s/it] 68%|██████▊   | 321/469 [45:31<20:32,  8.32s/it]                                                 {'loss': 0.2264, 'learning_rate': 4.801590118365383e-05, 'epoch': 0.68}
 68%|██████▊   | 321/469 [45:32<20:32,  8.32s/it] 69%|██████▊   | 322/469 [45:40<20:15,  8.27s/it]                                                 {'loss': 0.3029, 'learning_rate': 4.7426016902263636e-05, 'epoch': 0.69}
 69%|██████▊   | 322/469 [45:40<20:15,  8.27s/it] 69%|██████▉   | 323/469 [45:48<20:01,  8.23s/it]                                                 {'loss': 0.3094, 'learning_rate': 4.683865004962452e-05, 'epoch': 0.69}
 69%|██████▉   | 323/469 [45:48<20:01,  8.23s/it] 69%|██████▉   | 324/469 [45:56<20:00,  8.28s/it]                                                 {'loss': 0.2468, 'learning_rate': 4.6253828750944375e-05, 'epoch': 0.69}
 69%|██████▉   | 324/469 [45:56<20:00,  8.28s/it] 69%|██████▉   | 325/469 [46:05<20:10,  8.41s/it]                                                 {'loss': 0.3269, 'learning_rate': 4.567158100954083e-05, 'epoch': 0.69}
 69%|██████▉   | 325/469 [46:05<20:10,  8.41s/it] 70%|██████▉   | 326/469 [46:13<20:02,  8.41s/it]                                                 {'loss': 0.3256, 'learning_rate': 4.509193470550056e-05, 'epoch': 0.7}
 70%|██████▉   | 326/469 [46:13<20:02,  8.41s/it][2024-11-12 17:56:31,220] [WARNING] [stage3.py:1991:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
 70%|██████▉   | 327/469 [46:22<20:24,  8.62s/it]                                                 {'loss': 0.3481, 'learning_rate': 4.4514917594344184e-05, 'epoch': 0.7}
 70%|██████▉   | 327/469 [46:22<20:24,  8.62s/it] 70%|██████▉   | 328/469 [46:31<20:02,  8.53s/it]                                                 {'loss': 0.3692, 'learning_rate': 4.3940557305697226e-05, 'epoch': 0.7}
 70%|██████▉   | 328/469 [46:31<20:02,  8.53s/it] 70%|███████   | 329/469 [46:39<19:42,  8.44s/it]                                                 {'loss': 0.3753, 'learning_rate': 4.3368881341967135e-05, 'epoch': 0.7}
 70%|███████   | 329/469 [46:39<19:42,  8.44s/it] 70%|███████   | 330/469 [46:47<19:23,  8.37s/it]                                                 {'loss': 0.3392, 'learning_rate': 4.2799917077026394e-05, 'epoch': 0.7}
 70%|███████   | 330/469 [46:47<19:23,  8.37s/it] 71%|███████   | 331/469 [46:56<19:30,  8.48s/it]                                                 {'loss': 0.3306, 'learning_rate': 4.223369175490162e-05, 'epoch': 0.71}
 71%|███████   | 331/469 [46:56<19:30,  8.48s/it] 71%|███████   | 332/469 [47:04<19:24,  8.50s/it]                                                 {'loss': 0.2964, 'learning_rate': 4.167023248846925e-05, 'epoch': 0.71}
 71%|███████   | 332/469 [47:04<19:24,  8.50s/it] 71%|███████   | 333/469 [47:13<19:10,  8.46s/it]                                                 {'loss': 0.358, 'learning_rate': 4.110956625815713e-05, 'epoch': 0.71}
 71%|███████   | 333/469 [47:13<19:10,  8.46s/it] 71%|███████   | 334/469 [47:21<18:58,  8.43s/it]                                                 {'loss': 0.3284, 'learning_rate': 4.055171991065262e-05, 'epoch': 0.71}
 71%|███████   | 334/469 [47:21<18:58,  8.43s/it] 71%|███████▏  | 335/469 [47:29<18:42,  8.38s/it]                                                 {'loss': 0.3319, 'learning_rate': 3.9996720157617094e-05, 'epoch': 0.71}
 71%|███████▏  | 335/469 [47:29<18:42,  8.38s/it] 72%|███████▏  | 336/469 [47:37<18:23,  8.30s/it]                                                 {'loss': 0.3518, 'learning_rate': 3.9444593574406915e-05, 'epoch': 0.72}
 72%|███████▏  | 336/469 [47:37<18:23,  8.30s/it] 72%|███████▏  | 337/469 [47:46<18:24,  8.37s/it]                                                 {'loss': 0.3669, 'learning_rate': 3.8895366598800896e-05, 'epoch': 0.72}
 72%|███████▏  | 337/469 [47:46<18:24,  8.37s/it] 72%|███████▏  | 338/469 [47:55<18:23,  8.42s/it]                                                 {'loss': 0.2742, 'learning_rate': 3.834906552973424e-05, 'epoch': 0.72}
 72%|███████▏  | 338/469 [47:55<18:23,  8.42s/it] 72%|███████▏  | 339/469 [48:03<18:13,  8.41s/it]                                                 {'loss': 0.3359, 'learning_rate': 3.780571652603949e-05, 'epoch': 0.72}
 72%|███████▏  | 339/469 [48:03<18:13,  8.41s/it] 72%|███████▏  | 340/469 [48:11<18:02,  8.39s/it]                                                 {'loss': 0.3013, 'learning_rate': 3.726534560519381e-05, 'epoch': 0.72}
 72%|███████▏  | 340/469 [48:11<18:02,  8.39s/it] 73%|███████▎  | 341/469 [48:20<17:51,  8.37s/it]                                                 {'loss': 0.3732, 'learning_rate': 3.672797864207316e-05, 'epoch': 0.73}
 73%|███████▎  | 341/469 [48:20<17:51,  8.37s/it] 73%|███████▎  | 342/469 [48:28<17:40,  8.35s/it]                                                 {'loss': 0.3733, 'learning_rate': 3.619364136771337e-05, 'epoch': 0.73}
 73%|███████▎  | 342/469 [48:28<17:40,  8.35s/it] 73%|███████▎  | 343/469 [48:36<17:31,  8.34s/it]                                                 {'loss': 0.2974, 'learning_rate': 3.566235936807808e-05, 'epoch': 0.73}
 73%|███████▎  | 343/469 [48:36<17:31,  8.34s/it] 73%|███████▎  | 344/469 [48:45<17:39,  8.48s/it]                                                 {'loss': 0.3622, 'learning_rate': 3.513415808283341e-05, 'epoch': 0.73}
 73%|███████▎  | 344/469 [48:45<17:39,  8.48s/it] 74%|███████▎  | 345/469 [48:53<17:31,  8.48s/it]                                                 {'loss': 0.3594, 'learning_rate': 3.460906280413007e-05, 'epoch': 0.74}
 74%|███████▎  | 345/469 [48:54<17:31,  8.48s/it] 74%|███████▍  | 346/469 [49:02<17:18,  8.44s/it]                                                 {'loss': 0.2331, 'learning_rate': 3.4087098675392104e-05, 'epoch': 0.74}
 74%|███████▍  | 346/469 [49:02<17:18,  8.44s/it] 74%|███████▍  | 347/469 [49:10<17:03,  8.39s/it]                                                 {'loss': 0.3674, 'learning_rate': 3.3568290690113034e-05, 'epoch': 0.74}
 74%|███████▍  | 347/469 [49:10<17:03,  8.39s/it] 74%|███████▍  | 348/469 [49:18<16:53,  8.37s/it]                                                 {'loss': 0.3677, 'learning_rate': 3.305266369065901e-05, 'epoch': 0.74}
 74%|███████▍  | 348/469 [49:18<16:53,  8.37s/it] 74%|███████▍  | 349/469 [49:27<16:48,  8.40s/it]                                                 {'loss': 0.3459, 'learning_rate': 3.25402423670793e-05, 'epoch': 0.74}
 74%|███████▍  | 349/469 [49:27<16:48,  8.40s/it] 75%|███████▍  | 350/469 [49:35<16:44,  8.44s/it]                                                 {'loss': 0.3295, 'learning_rate': 3.2031051255924085e-05, 'epoch': 0.75}
 75%|███████▍  | 350/469 [49:35<16:44,  8.44s/it] 75%|███████▍  | 351/469 [49:44<16:44,  8.51s/it]                                                 {'loss': 0.3399, 'learning_rate': 3.1525114739069415e-05, 'epoch': 0.75}
 75%|███████▍  | 351/469 [49:44<16:44,  8.51s/it] 75%|███████▌  | 352/469 [49:52<16:27,  8.44s/it]                                                 {'loss': 0.3235, 'learning_rate': 3.102245704254995e-05, 'epoch': 0.75}
 75%|███████▌  | 352/469 [49:52<16:27,  8.44s/it] 75%|███████▌  | 353/469 [50:01<16:15,  8.41s/it]                                                 {'loss': 0.3668, 'learning_rate': 3.0523102235398714e-05, 'epoch': 0.75}
 75%|███████▌  | 353/469 [50:01<16:15,  8.41s/it] 75%|███████▌  | 354/469 [50:09<15:59,  8.34s/it]                                                 {'loss': 0.252, 'learning_rate': 3.002707422849472e-05, 'epoch': 0.75}
 75%|███████▌  | 354/469 [50:09<15:59,  8.34s/it] 76%|███████▌  | 355/469 [50:18<16:00,  8.43s/it]                                                 {'loss': 0.331, 'learning_rate': 2.9534396773417994e-05, 'epoch': 0.76}
 76%|███████▌  | 355/469 [50:18<16:00,  8.43s/it] 76%|███████▌  | 356/469 [50:26<15:56,  8.46s/it]                                                 {'loss': 0.3178, 'learning_rate': 2.9045093461312258e-05, 'epoch': 0.76}
 76%|███████▌  | 356/469 [50:26<15:56,  8.46s/it] 76%|███████▌  | 357/469 [50:35<15:50,  8.49s/it]                                                 {'loss': 0.3422, 'learning_rate': 2.855918772175522e-05, 'epoch': 0.76}
 76%|███████▌  | 357/469 [50:35<15:50,  8.49s/it] 76%|███████▋  | 358/469 [50:43<15:40,  8.47s/it]                                                 {'loss': 0.283, 'learning_rate': 2.8076702821636867e-05, 'epoch': 0.76}
 76%|███████▋  | 358/469 [50:43<15:40,  8.47s/it] 77%|███████▋  | 359/469 [50:51<15:26,  8.43s/it]                                                 {'loss': 0.3367, 'learning_rate': 2.7597661864045233e-05, 'epoch': 0.77}
 77%|███████▋  | 359/469 [50:51<15:26,  8.43s/it] 77%|███████▋  | 360/469 [51:00<15:25,  8.49s/it]                                                 {'loss': 0.317, 'learning_rate': 2.7122087787160166e-05, 'epoch': 0.77}
 77%|███████▋  | 360/469 [51:00<15:25,  8.49s/it] 77%|███████▋  | 361/469 [51:08<15:09,  8.42s/it]                                                 {'loss': 0.3415, 'learning_rate': 2.6650003363154963e-05, 'epoch': 0.77}
 77%|███████▋  | 361/469 [51:08<15:09,  8.42s/it] 77%|███████▋  | 362/469 [51:17<15:01,  8.43s/it]                                                 {'loss': 0.3221, 'learning_rate': 2.6181431197105998e-05, 'epoch': 0.77}
 77%|███████▋  | 362/469 [51:17<15:01,  8.43s/it] 77%|███████▋  | 363/469 [51:25<14:59,  8.49s/it]                                                 {'loss': 0.4133, 'learning_rate': 2.5716393725910215e-05, 'epoch': 0.77}
 77%|███████▋  | 363/469 [51:25<14:59,  8.49s/it] 78%|███████▊  | 364/469 [51:34<14:51,  8.49s/it]                                                 {'loss': 0.3609, 'learning_rate': 2.5254913217210886e-05, 'epoch': 0.78}
 78%|███████▊  | 364/469 [51:34<14:51,  8.49s/it] 78%|███████▊  | 365/469 [51:42<14:41,  8.47s/it]                                                 {'loss': 0.3731, 'learning_rate': 2.47970117683313e-05, 'epoch': 0.78}
 78%|███████▊  | 365/469 [51:42<14:41,  8.47s/it] 78%|███████▊  | 366/469 [51:50<14:24,  8.40s/it]                                                 {'loss': 0.2448, 'learning_rate': 2.434271130521666e-05, 'epoch': 0.78}
 78%|███████▊  | 366/469 [51:51<14:24,  8.40s/it] 78%|███████▊  | 367/469 [51:59<14:10,  8.34s/it]                                                 {'loss': 0.3427, 'learning_rate': 2.389203358138419e-05, 'epoch': 0.78}
 78%|███████▊  | 367/469 [51:59<14:10,  8.34s/it] 78%|███████▊  | 368/469 [52:07<13:58,  8.30s/it]                                                 {'loss': 0.3147, 'learning_rate': 2.3445000176881537e-05, 'epoch': 0.78}
 78%|███████▊  | 368/469 [52:07<13:58,  8.30s/it] 79%|███████▊  | 369/469 [52:16<14:03,  8.43s/it]                                                 {'loss': 0.3853, 'learning_rate': 2.3001632497253424e-05, 'epoch': 0.79}
 79%|███████▊  | 369/469 [52:16<14:03,  8.43s/it] 79%|███████▉  | 370/469 [52:24<14:01,  8.50s/it]                                                 {'loss': 0.3384, 'learning_rate': 2.2561951772516587e-05, 'epoch': 0.79}
 79%|███████▉  | 370/469 [52:24<14:01,  8.50s/it] 79%|███████▉  | 371/469 [52:32<13:42,  8.40s/it]                                                 {'loss': 0.3267, 'learning_rate': 2.2125979056143364e-05, 'epoch': 0.79}
 79%|███████▉  | 371/469 [52:33<13:42,  8.40s/it] 79%|███████▉  | 372/469 [52:41<13:28,  8.33s/it]                                                 {'loss': 0.3061, 'learning_rate': 2.169373522405349e-05, 'epoch': 0.79}
 79%|███████▉  | 372/469 [52:41<13:28,  8.33s/it] 80%|███████▉  | 373/469 [52:49<13:20,  8.34s/it]                                                 {'loss': 0.3361, 'learning_rate': 2.1265240973614486e-05, 'epoch': 0.8}
 80%|███████▉  | 373/469 [52:49<13:20,  8.34s/it] 80%|███████▉  | 374/469 [52:57<13:12,  8.34s/it]                                                 {'loss': 0.4002, 'learning_rate': 2.0840516822650614e-05, 'epoch': 0.8}
 80%|███████▉  | 374/469 [52:57<13:12,  8.34s/it] 80%|███████▉  | 375/469 [53:06<13:13,  8.44s/it]                                                 {'loss': 0.3038, 'learning_rate': 2.0419583108460418e-05, 'epoch': 0.8}
 80%|███████▉  | 375/469 [53:06<13:13,  8.44s/it] 80%|████████  | 376/469 [53:15<13:10,  8.50s/it]                                                 {'loss': 0.339, 'learning_rate': 2.0002459986842825e-05, 'epoch': 0.8}
 80%|████████  | 376/469 [53:15<13:10,  8.50s/it] 80%|████████  | 377/469 [53:23<12:53,  8.41s/it]                                                 {'loss': 0.2829, 'learning_rate': 1.958916743113214e-05, 'epoch': 0.8}
 80%|████████  | 377/469 [53:23<12:53,  8.41s/it] 81%|████████  | 378/469 [53:31<12:43,  8.39s/it]                                                 {'loss': 0.3756, 'learning_rate': 1.9179725231241564e-05, 'epoch': 0.81}
 81%|████████  | 378/469 [53:31<12:43,  8.39s/it] 81%|████████  | 379/469 [53:39<12:30,  8.33s/it]                                                 {'loss': 0.3378, 'learning_rate': 1.877415299271561e-05, 'epoch': 0.81}
 81%|████████  | 379/469 [53:39<12:30,  8.33s/it] 81%|████████  | 380/469 [53:47<12:15,  8.26s/it]                                                 {'loss': 0.3358, 'learning_rate': 1.8372470135791344e-05, 'epoch': 0.81}
 81%|████████  | 380/469 [53:48<12:15,  8.26s/it] 81%|████████  | 381/469 [53:56<12:14,  8.34s/it]                                                 {'loss': 0.3161, 'learning_rate': 1.7974695894468384e-05, 'epoch': 0.81}
 81%|████████  | 381/469 [53:56<12:14,  8.34s/it] 81%|████████▏ | 382/469 [54:05<12:12,  8.42s/it]                                                 {'loss': 0.3131, 'learning_rate': 1.7580849315588068e-05, 'epoch': 0.81}
 81%|████████▏ | 382/469 [54:05<12:12,  8.42s/it] 82%|████████▏ | 383/469 [54:13<12:05,  8.44s/it]                                                 {'loss': 0.3406, 'learning_rate': 1.7190949257921196e-05, 'epoch': 0.82}
 82%|████████▏ | 383/469 [54:13<12:05,  8.44s/it] 82%|████████▏ | 384/469 [54:21<11:52,  8.38s/it]                                                 {'loss': 0.3745, 'learning_rate': 1.680501439126525e-05, 'epoch': 0.82}
 82%|████████▏ | 384/469 [54:21<11:52,  8.38s/it] 82%|████████▏ | 385/469 [54:30<11:43,  8.38s/it]                                                 {'loss': 0.3534, 'learning_rate': 1.642306319555027e-05, 'epoch': 0.82}
 82%|████████▏ | 385/469 [54:30<11:43,  8.38s/it] 82%|████████▏ | 386/469 [54:38<11:31,  8.33s/it]                                                 {'loss': 0.3465, 'learning_rate': 1.6045113959953985e-05, 'epoch': 0.82}
 82%|████████▏ | 386/469 [54:38<11:31,  8.33s/it] 83%|████████▎ | 387/469 [54:46<11:25,  8.36s/it]                                                 {'loss': 0.3173, 'learning_rate': 1.5671184782026106e-05, 'epoch': 0.83}
 83%|████████▎ | 387/469 [54:46<11:25,  8.36s/it] 83%|████████▎ | 388/469 [54:55<11:24,  8.45s/it]                                                 {'loss': 0.3176, 'learning_rate': 1.530129356682175e-05, 'epoch': 0.83}
 83%|████████▎ | 388/469 [54:55<11:24,  8.45s/it] 83%|████████▎ | 389/469 [55:03<11:13,  8.42s/it]                                                 {'loss': 0.3287, 'learning_rate': 1.4935458026043959e-05, 'epoch': 0.83}
 83%|████████▎ | 389/469 [55:03<11:13,  8.42s/it] 83%|████████▎ | 390/469 [55:12<11:10,  8.49s/it]                                                 {'loss': 0.4098, 'learning_rate': 1.457369567719581e-05, 'epoch': 0.83}
 83%|████████▎ | 390/469 [55:12<11:10,  8.49s/it] 83%|████████▎ | 391/469 [55:20<10:59,  8.46s/it]                                                 {'loss': 0.3224, 'learning_rate': 1.4216023842741455e-05, 'epoch': 0.83}
 83%|████████▎ | 391/469 [55:21<10:59,  8.46s/it] 84%|████████▎ | 392/469 [55:29<10:49,  8.44s/it]                                                 {'loss': 0.3269, 'learning_rate': 1.3862459649276715e-05, 'epoch': 0.84}
 84%|████████▎ | 392/469 [55:29<10:49,  8.44s/it] 84%|████████▍ | 393/469 [55:37<10:38,  8.40s/it]                                                 {'loss': 0.3151, 'learning_rate': 1.3513020026709023e-05, 'epoch': 0.84}
 84%|████████▍ | 393/469 [55:37<10:38,  8.40s/it] 84%|████████▍ | 394/469 [55:46<10:33,  8.44s/it]                                                 {'loss': 0.3352, 'learning_rate': 1.3167721707446678e-05, 'epoch': 0.84}
 84%|████████▍ | 394/469 [55:46<10:33,  8.44s/it] 84%|████████▍ | 395/469 [55:54<10:31,  8.53s/it]                                                 {'loss': 0.3088, 'learning_rate': 1.2826581225597767e-05, 'epoch': 0.84}
 84%|████████▍ | 395/469 [55:54<10:31,  8.53s/it] 84%|████████▍ | 396/469 [56:03<10:20,  8.50s/it]                                                 {'loss': 0.3492, 'learning_rate': 1.248961491617826e-05, 'epoch': 0.84}
 84%|████████▍ | 396/469 [56:03<10:20,  8.50s/it] 85%|████████▍ | 397/469 [56:11<10:07,  8.44s/it]                                                 {'loss': 0.323, 'learning_rate': 1.2156838914330072e-05, 'epoch': 0.85}
 85%|████████▍ | 397/469 [56:11<10:07,  8.44s/it] 85%|████████▍ | 398/469 [56:20<09:58,  8.43s/it]                                                 {'loss': 0.3757, 'learning_rate': 1.1828269154548244e-05, 'epoch': 0.85}
 85%|████████▍ | 398/469 [56:20<09:58,  8.43s/it] 85%|████████▌ | 399/469 [56:28<09:51,  8.45s/it]                                                 {'loss': 0.3972, 'learning_rate': 1.1503921369918091e-05, 'epoch': 0.85}
 85%|████████▌ | 399/469 [56:28<09:51,  8.45s/it] 85%|████████▌ | 400/469 [56:36<09:43,  8.45s/it]                                                 {'loss': 0.2795, 'learning_rate': 1.118381109136174e-05, 'epoch': 0.85}
 85%|████████▌ | 400/469 [56:37<09:43,  8.45s/it] 86%|████████▌ | 401/469 [56:45<09:35,  8.47s/it]                                                 {'loss': 0.231, 'learning_rate': 1.0867953646894525e-05, 'epoch': 0.86}
 86%|████████▌ | 401/469 [56:45<09:35,  8.47s/it] 86%|████████▌ | 402/469 [56:53<09:27,  8.47s/it]                                                 {'loss': 0.3029, 'learning_rate': 1.055636416089102e-05, 'epoch': 0.86}
 86%|████████▌ | 402/469 [56:54<09:27,  8.47s/it] 86%|████████▌ | 403/469 [57:02<09:15,  8.42s/it]                                                 {'loss': 0.3074, 'learning_rate': 1.0249057553360742e-05, 'epoch': 0.86}
 86%|████████▌ | 403/469 [57:02<09:15,  8.42s/it] 86%|████████▌ | 404/469 [57:10<09:04,  8.38s/it]                                                 {'loss': 0.2508, 'learning_rate': 9.946048539233865e-06, 'epoch': 0.86}
 86%|████████▌ | 404/469 [57:10<09:04,  8.38s/it] 86%|████████▋ | 405/469 [57:18<08:53,  8.34s/it]                                                 {'loss': 0.369, 'learning_rate': 9.647351627656543e-06, 'epoch': 0.86}
 86%|████████▋ | 405/469 [57:18<08:53,  8.34s/it] 87%|████████▋ | 406/469 [57:27<08:47,  8.37s/it]                                                 {'loss': 0.3176, 'learning_rate': 9.352981121296134e-06, 'epoch': 0.87}
 87%|████████▋ | 406/469 [57:27<08:47,  8.37s/it] 87%|████████▋ | 407/469 [57:35<08:43,  8.45s/it]                                                 {'loss': 0.3303, 'learning_rate': 9.062951115656403e-06, 'epoch': 0.87}
 87%|████████▋ | 407/469 [57:35<08:43,  8.45s/it] 87%|████████▋ | 408/469 [57:44<08:35,  8.45s/it]                                                 {'loss': 0.2335, 'learning_rate': 8.777275498402548e-06, 'epoch': 0.87}
 87%|████████▋ | 408/469 [57:44<08:35,  8.45s/it] 87%|████████▋ | 409/469 [57:52<08:24,  8.40s/it]                                                 {'loss': 0.3335, 'learning_rate': 8.495967948696192e-06, 'epoch': 0.87}
 87%|████████▋ | 409/469 [57:52<08:24,  8.40s/it] 87%|████████▋ | 410/469 [58:00<08:12,  8.34s/it]                                                 {'loss': 0.3078, 'learning_rate': 8.219041936540395e-06, 'epoch': 0.87}
 87%|████████▋ | 410/469 [58:00<08:12,  8.34s/it] 88%|████████▊ | 411/469 [58:09<08:03,  8.33s/it]                                                 {'loss': 0.3876, 'learning_rate': 7.946510722134692e-06, 'epoch': 0.88}
 88%|████████▊ | 411/469 [58:09<08:03,  8.33s/it] 88%|████████▊ | 412/469 [58:17<07:53,  8.31s/it]                                                 {'loss': 0.3025, 'learning_rate': 7.678387355240057e-06, 'epoch': 0.88}
 88%|████████▊ | 412/469 [58:17<07:53,  8.31s/it] 88%|████████▊ | 413/469 [58:26<07:51,  8.42s/it]                                                 {'loss': 0.2864, 'learning_rate': 7.4146846745541506e-06, 'epoch': 0.88}
 88%|████████▊ | 413/469 [58:26<07:51,  8.42s/it] 88%|████████▊ | 414/469 [58:34<07:47,  8.49s/it]                                                 {'loss': 0.3478, 'learning_rate': 7.155415307096458e-06, 'epoch': 0.88}
 88%|████████▊ | 414/469 [58:34<07:47,  8.49s/it] 88%|████████▊ | 415/469 [58:42<07:33,  8.40s/it]                                                 {'loss': 0.2512, 'learning_rate': 6.900591667603751e-06, 'epoch': 0.88}
 88%|████████▊ | 415/469 [58:43<07:33,  8.40s/it] 89%|████████▊ | 416/469 [58:51<07:25,  8.41s/it]                                                 {'loss': 0.3331, 'learning_rate': 6.650225957935552e-06, 'epoch': 0.89}
 89%|████████▊ | 416/469 [58:51<07:25,  8.41s/it] 89%|████████▉ | 417/469 [58:59<07:14,  8.35s/it]                                                 {'loss': 0.2694, 'learning_rate': 6.40433016648988e-06, 'epoch': 0.89}
 89%|████████▉ | 417/469 [58:59<07:14,  8.35s/it] 89%|████████▉ | 418/469 [59:07<07:04,  8.32s/it]                                                 {'loss': 0.3424, 'learning_rate': 6.162916067629254e-06, 'epoch': 0.89}
 89%|████████▉ | 418/469 [59:07<07:04,  8.32s/it] 89%|████████▉ | 419/469 [59:16<06:58,  8.38s/it]                                                 {'loss': 0.3039, 'learning_rate': 5.925995221116853e-06, 'epoch': 0.89}
 89%|████████▉ | 419/469 [59:16<06:58,  8.38s/it] 90%|████████▉ | 420/469 [59:24<06:54,  8.46s/it]                                                 {'loss': 0.3021, 'learning_rate': 5.693578971562963e-06, 'epoch': 0.9}
 90%|████████▉ | 420/469 [59:25<06:54,  8.46s/it] 90%|████████▉ | 421/469 [59:33<06:43,  8.41s/it]                                                 {'loss': 0.3902, 'learning_rate': 5.465678447881828e-06, 'epoch': 0.9}
 90%|████████▉ | 421/469 [59:33<06:43,  8.41s/it] 90%|████████▉ | 422/469 [59:41<06:35,  8.41s/it]                                                 {'loss': 0.2887, 'learning_rate': 5.242304562758704e-06, 'epoch': 0.9}
 90%|████████▉ | 422/469 [59:41<06:35,  8.41s/it] 90%|█████████ | 423/469 [59:49<06:24,  8.35s/it]                                                 {'loss': 0.3438, 'learning_rate': 5.023468012127364e-06, 'epoch': 0.9}
 90%|█████████ | 423/469 [59:49<06:24,  8.35s/it] 90%|█████████ | 424/469 [59:58<06:15,  8.33s/it]                                                 {'loss': 0.3154, 'learning_rate': 4.8091792746578935e-06, 'epoch': 0.9}
 90%|█████████ | 424/469 [59:58<06:15,  8.33s/it] 91%|█████████ | 425/469 [1:00:06<06:08,  8.37s/it]                                                   {'loss': 0.3078, 'learning_rate': 4.599448611254964e-06, 'epoch': 0.91}
 91%|█████████ | 425/469 [1:00:06<06:08,  8.37s/it] 91%|█████████ | 426/469 [1:00:15<06:03,  8.46s/it]                                                   {'loss': 0.3245, 'learning_rate': 4.394286064566511e-06, 'epoch': 0.91}
 91%|█████████ | 426/469 [1:00:15<06:03,  8.46s/it] 91%|█████████ | 427/469 [1:00:23<05:55,  8.46s/it]                                                   {'loss': 0.4069, 'learning_rate': 4.193701458502807e-06, 'epoch': 0.91}
 91%|█████████ | 427/469 [1:00:23<05:55,  8.46s/it] 91%|█████████▏| 428/469 [1:00:32<05:45,  8.43s/it]                                                   {'loss': 0.3058, 'learning_rate': 3.997704397766122e-06, 'epoch': 0.91}
 91%|█████████▏| 428/469 [1:00:32<05:45,  8.43s/it] 91%|█████████▏| 429/469 [1:00:40<05:35,  8.40s/it]                                                   {'loss': 0.3131, 'learning_rate': 3.80630426739077e-06, 'epoch': 0.91}
 91%|█████████▏| 429/469 [1:00:40<05:35,  8.40s/it] 92%|█████████▏| 430/469 [1:00:48<05:27,  8.39s/it]                                                   {'loss': 0.3912, 'learning_rate': 3.6195102322937545e-06, 'epoch': 0.92}
 92%|█████████▏| 430/469 [1:00:48<05:27,  8.39s/it] 92%|█████████▏| 431/469 [1:00:57<05:18,  8.38s/it]                                                   {'loss': 0.2741, 'learning_rate': 3.4373312368358944e-06, 'epoch': 0.92}
 92%|█████████▏| 431/469 [1:00:57<05:18,  8.38s/it] 92%|█████████▏| 432/469 [1:01:06<05:16,  8.54s/it]                                                   {'loss': 0.346, 'learning_rate': 3.259776004393533e-06, 'epoch': 0.92}
 92%|█████████▏| 432/469 [1:01:06<05:16,  8.54s/it] 92%|█████████▏| 433/469 [1:01:14<05:10,  8.61s/it]                                                   {'loss': 0.3274, 'learning_rate': 3.086853036940862e-06, 'epoch': 0.92}
 92%|█████████▏| 433/469 [1:01:14<05:10,  8.61s/it] 93%|█████████▎| 434/469 [1:01:23<04:58,  8.54s/it]                                                   {'loss': 0.3137, 'learning_rate': 2.9185706146428017e-06, 'epoch': 0.93}
 93%|█████████▎| 434/469 [1:01:23<04:58,  8.54s/it] 93%|█████████▎| 435/469 [1:01:31<04:48,  8.48s/it]                                                   {'loss': 0.3623, 'learning_rate': 2.754936795458485e-06, 'epoch': 0.93}
 93%|█████████▎| 435/469 [1:01:31<04:48,  8.48s/it] 93%|█████████▎| 436/469 [1:01:39<04:37,  8.40s/it]                                                   {'loss': 0.3681, 'learning_rate': 2.5959594147554667e-06, 'epoch': 0.93}
 93%|█████████▎| 436/469 [1:01:39<04:37,  8.40s/it] 93%|█████████▎| 437/469 [1:01:48<04:29,  8.41s/it]                                                   {'loss': 0.3714, 'learning_rate': 2.4416460849345123e-06, 'epoch': 0.93}
 93%|█████████▎| 437/469 [1:01:48<04:29,  8.41s/it] 93%|█████████▎| 438/469 [1:01:56<04:21,  8.45s/it]                                                   {'loss': 0.3516, 'learning_rate': 2.2920041950650783e-06, 'epoch': 0.93}
 93%|█████████▎| 438/469 [1:01:56<04:21,  8.45s/it] 94%|█████████▎| 439/469 [1:02:05<04:15,  8.52s/it]                                                   {'loss': 0.3296, 'learning_rate': 2.1470409105315283e-06, 'epoch': 0.94}
 94%|█████████▎| 439/469 [1:02:05<04:15,  8.52s/it] 94%|█████████▍| 440/469 [1:02:14<04:07,  8.53s/it]                                                   {'loss': 0.301, 'learning_rate': 2.0067631726899962e-06, 'epoch': 0.94}
 94%|█████████▍| 440/469 [1:02:14<04:07,  8.53s/it] 94%|█████████▍| 441/469 [1:02:22<03:56,  8.44s/it]                                                   {'loss': 0.2581, 'learning_rate': 1.8711776985360308e-06, 'epoch': 0.94}
 94%|█████████▍| 441/469 [1:02:22<03:56,  8.44s/it] 94%|█████████▍| 442/469 [1:02:30<03:46,  8.38s/it]                                                   {'loss': 0.2598, 'learning_rate': 1.7402909803829525e-06, 'epoch': 0.94}
 94%|█████████▍| 442/469 [1:02:30<03:46,  8.38s/it] 94%|█████████▍| 443/469 [1:02:38<03:37,  8.35s/it]                                                   {'loss': 0.3691, 'learning_rate': 1.61410928555098e-06, 'epoch': 0.94}
 94%|█████████▍| 443/469 [1:02:38<03:37,  8.35s/it] 95%|█████████▍| 444/469 [1:02:47<03:29,  8.38s/it]                                                   {'loss': 0.3291, 'learning_rate': 1.4926386560671358e-06, 'epoch': 0.95}
 95%|█████████▍| 444/469 [1:02:47<03:29,  8.38s/it] 95%|█████████▍| 445/469 [1:02:55<03:22,  8.43s/it]                                                   {'loss': 0.3007, 'learning_rate': 1.3758849083759352e-06, 'epoch': 0.95}
 95%|█████████▍| 445/469 [1:02:55<03:22,  8.43s/it] 95%|█████████▌| 446/469 [1:03:04<03:15,  8.49s/it]                                                   {'loss': 0.3438, 'learning_rate': 1.2638536330608408e-06, 'epoch': 0.95}
 95%|█████████▌| 446/469 [1:03:04<03:15,  8.49s/it] 95%|█████████▌| 447/469 [1:03:12<03:04,  8.40s/it]                                                   {'loss': 0.2015, 'learning_rate': 1.1565501945766222e-06, 'epoch': 0.95}
 95%|█████████▌| 447/469 [1:03:12<03:04,  8.40s/it] 96%|█████████▌| 448/469 [1:03:20<02:56,  8.39s/it]                                                   {'loss': 0.3232, 'learning_rate': 1.053979730992416e-06, 'epoch': 0.96}
 96%|█████████▌| 448/469 [1:03:20<02:56,  8.39s/it] 96%|█████████▌| 449/469 [1:03:29<02:46,  8.35s/it]                                                   {'loss': 0.328, 'learning_rate': 9.56147153745779e-07, 'epoch': 0.96}
 96%|█████████▌| 449/469 [1:03:29<02:46,  8.35s/it] 96%|█████████▌| 450/469 [1:03:37<02:38,  8.35s/it]                                                   {'loss': 0.3348, 'learning_rate': 8.630571474074311e-07, 'epoch': 0.96}
 96%|█████████▌| 450/469 [1:03:37<02:38,  8.35s/it] 96%|█████████▌| 451/469 [1:03:46<02:31,  8.44s/it]                                                   {'loss': 0.2863, 'learning_rate': 7.747141694570026e-07, 'epoch': 0.96}
 96%|█████████▌| 451/469 [1:03:46<02:31,  8.44s/it] 96%|█████████▋| 452/469 [1:03:54<02:24,  8.51s/it]                                                   {'loss': 0.3501, 'learning_rate': 6.911224500695702e-07, 'epoch': 0.96}
 96%|█████████▋| 452/469 [1:03:54<02:24,  8.51s/it] 97%|█████████▋| 453/469 [1:04:03<02:15,  8.49s/it]                                                   {'loss': 0.3328, 'learning_rate': 6.122859919130974e-07, 'epoch': 0.97}
 97%|█████████▋| 453/469 [1:04:03<02:15,  8.49s/it] 97%|█████████▋| 454/469 [1:04:11<02:06,  8.41s/it]                                                   {'loss': 0.3883, 'learning_rate': 5.382085699567552e-07, 'epoch': 0.97}
 97%|█████████▋| 454/469 [1:04:11<02:06,  8.41s/it] 97%|█████████▋| 455/469 [1:04:19<01:57,  8.38s/it]                                                   {'loss': 0.2857, 'learning_rate': 4.6889373129022085e-07, 'epoch': 0.97}
 97%|█████████▋| 455/469 [1:04:19<01:57,  8.38s/it] 97%|█████████▋| 456/469 [1:04:28<01:48,  8.36s/it]                                                   {'loss': 0.3226, 'learning_rate': 4.0434479495378155e-07, 'epoch': 0.97}
 97%|█████████▋| 456/469 [1:04:28<01:48,  8.36s/it] 97%|█████████▋| 457/469 [1:04:36<01:40,  8.37s/it]                                                   {'loss': 0.2834, 'learning_rate': 3.445648517793942e-07, 'epoch': 0.97}
 97%|█████████▋| 457/469 [1:04:36<01:40,  8.37s/it] 98%|█████████▊| 458/469 [1:04:45<01:33,  8.47s/it]                                                   {'loss': 0.3414, 'learning_rate': 2.895567642427488e-07, 'epoch': 0.98}
 98%|█████████▊| 458/469 [1:04:45<01:33,  8.47s/it] 98%|█████████▊| 459/469 [1:04:53<01:24,  8.46s/it]                                                   {'loss': 0.3895, 'learning_rate': 2.3932316632614416e-07, 'epoch': 0.98}
 98%|█████████▊| 459/469 [1:04:53<01:24,  8.46s/it] 98%|█████████▊| 460/469 [1:05:02<01:15,  8.42s/it]                                                   {'loss': 0.3295, 'learning_rate': 1.9386646339238924e-07, 'epoch': 0.98}
 98%|█████████▊| 460/469 [1:05:02<01:15,  8.42s/it] 98%|█████████▊| 461/469 [1:05:10<01:06,  8.37s/it]                                                   {'loss': 0.3212, 'learning_rate': 1.5318883206962842e-07, 'epoch': 0.98}
 98%|█████████▊| 461/469 [1:05:10<01:06,  8.37s/it] 99%|█████████▊| 462/469 [1:05:18<00:58,  8.33s/it]                                                   {'loss': 0.2769, 'learning_rate': 1.1729222014709162e-07, 'epoch': 0.99}
 99%|█████████▊| 462/469 [1:05:18<00:58,  8.33s/it] 99%|█████████▊| 463/469 [1:05:27<00:50,  8.39s/it]                                                   {'loss': 0.332, 'learning_rate': 8.617834648185774e-08, 'epoch': 0.99}
 99%|█████████▊| 463/469 [1:05:27<00:50,  8.39s/it] 99%|█████████▉| 464/469 [1:05:35<00:42,  8.49s/it]                                                   {'loss': 0.3549, 'learning_rate': 5.984870091654271e-08, 'epoch': 0.99}
 99%|█████████▉| 464/469 [1:05:35<00:42,  8.49s/it] 99%|█████████▉| 465/469 [1:05:44<00:33,  8.50s/it]                                                   {'loss': 0.3219, 'learning_rate': 3.8304544207945495e-08, 'epoch': 0.99}
 99%|█████████▉| 465/469 [1:05:44<00:33,  8.50s/it] 99%|█████████▉| 466/469 [1:05:52<00:25,  8.40s/it]                                                   {'loss': 0.3426, 'learning_rate': 2.1546907966685236e-08, 'epoch': 0.99}
 99%|█████████▉| 466/469 [1:05:52<00:25,  8.40s/it]100%|█████████▉| 467/469 [1:06:00<00:16,  8.16s/it]                                                   {'loss': 0.3687, 'learning_rate': 9.576594607807465e-09, 'epoch': 1.0}
100%|█████████▉| 467/469 [1:06:00<00:16,  8.16s/it]100%|█████████▉| 468/469 [1:06:07<00:07,  7.96s/it]                                                   {'loss': 0.312, 'learning_rate': 2.3941773123814516e-09, 'epoch': 1.0}
100%|█████████▉| 468/469 [1:06:07<00:07,  7.96s/it]100%|██████████| 469/469 [1:06:15<00:00,  8.03s/it]                                                   {'loss': 0.2817, 'learning_rate': 0.0, 'epoch': 1.0}
100%|██████████| 469/469 [1:06:15<00:00,  8.03s/it]                                                   {'train_runtime': 3979.6775, 'train_samples_per_second': 3.769, 'train_steps_per_second': 0.118, 'train_loss': 0.3695980176043663, 'epoch': 1.0}
100%|██████████| 469/469 [1:06:15<00:00,  8.03s/it]100%|██████████| 469/469 [1:06:15<00:00,  8.48s/it]
Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.
Non-default generation parameters: {'max_length': 4096}
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
[1;34mwandb[0m:
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /cluster/home/jingma/LLaVA/wandb/offline-run-20241112_171005-qs6o2t23[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20241112_171005-qs6o2t23/logs[0m
[2024-11-12 18:16:40,659] [INFO] [launch.py:347:main] Process 359840 exits successfully.
[2024-11-12 18:16:41,660] [INFO] [launch.py:347:main] Process 359842 exits successfully.
[2024-11-12 18:16:41,661] [INFO] [launch.py:347:main] Process 359841 exits successfully.
[2024-11-12 18:16:42,662] [INFO] [launch.py:347:main] Process 359839 exits successfully.
